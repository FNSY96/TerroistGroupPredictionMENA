{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graduation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FNSY96/TerrorismEventsPrediction/blob/master/Graduation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t4_K6rWMxmH",
        "colab_type": "text"
      },
      "source": [
        "# **Python Imports**\n",
        "PLEASE PUT ALL LIBRARY IMPORTS IN THIS CELL **ONLY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SkGUUzMMr4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import glob\n",
        "import os\n",
        "import io\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts4MLZnIaj37",
        "colab_type": "code",
        "outputId": "b9e873fa-a2cf-473b-ebf9-9e12d6a1d7df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip3 install pandas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTQAhp_HNvyG",
        "colab_type": "text"
      },
      "source": [
        "# Data Set Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N13I8JpfMHc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdAFcrotUNTk",
        "colab_type": "code",
        "outputId": "74830a06-a5d8-4f61-9273-9df26620bfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# drive = GoogleDrive(gauth)\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "datadir  = 'drive/My Drive/GraduationProject/Data'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qsmoZ3eReyA",
        "colab_type": "text"
      },
      "source": [
        "###**GTD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvNzAiEaX4MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls drive/'My Drive'/GraduationProject/Data/gtd.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZjjGdaLVMkv",
        "colab_type": "text"
      },
      "source": [
        "# Pandas Data Frames\n",
        "Useful link : https://youtu.be/2AFGPdNn4FM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bYFOOr9U-7h",
        "colab_type": "text"
      },
      "source": [
        "## **GTD Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzPwkdhBZRZU",
        "colab_type": "code",
        "outputId": "838775cb-a6d3-4f2c-bafc-8126442f7751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "gtd_df = pd.read_csv(os.path.join(datadir, 'gtd.csv'),encoding='latin-1')\n",
        "print(gtd_df.columns.values)\n",
        "# print(gtd_df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['eventid' 'iyear' 'imonth' 'iday' 'approxdate' 'extended' 'resolution'\n",
            " 'country' 'country_txt' 'region' 'region_txt' 'provstate' 'city'\n",
            " 'latitude' 'longitude' 'specificity' 'vicinity' 'location' 'summary'\n",
            " 'crit1' 'crit2' 'crit3' 'doubtterr' 'alternative' 'alternative_txt'\n",
            " 'multiple' 'success' 'suicide' 'attacktype1' 'attacktype1_txt'\n",
            " 'attacktype2' 'attacktype2_txt' 'attacktype3' 'attacktype3_txt'\n",
            " 'targtype1' 'targtype1_txt' 'targsubtype1' 'targsubtype1_txt' 'corp1'\n",
            " 'target1' 'natlty1' 'natlty1_txt' 'targtype2' 'targtype2_txt'\n",
            " 'targsubtype2' 'targsubtype2_txt' 'corp2' 'target2' 'natlty2'\n",
            " 'natlty2_txt' 'targtype3' 'targtype3_txt' 'targsubtype3'\n",
            " 'targsubtype3_txt' 'corp3' 'target3' 'natlty3' 'natlty3_txt' 'gname'\n",
            " 'gsubname' 'gname2' 'gsubname2' 'gname3' 'gsubname3' 'motive'\n",
            " 'guncertain1' 'guncertain2' 'guncertain3' 'individual' 'nperps'\n",
            " 'nperpcap' 'claimed' 'claimmode' 'claimmode_txt' 'claim2' 'claimmode2'\n",
            " 'claimmode2_txt' 'claim3' 'claimmode3' 'claimmode3_txt' 'compclaim'\n",
            " 'weaptype1' 'weaptype1_txt' 'weapsubtype1' 'weapsubtype1_txt' 'weaptype2'\n",
            " 'weaptype2_txt' 'weapsubtype2' 'weapsubtype2_txt' 'weaptype3'\n",
            " 'weaptype3_txt' 'weapsubtype3' 'weapsubtype3_txt' 'weaptype4'\n",
            " 'weaptype4_txt' 'weapsubtype4' 'weapsubtype4_txt' 'weapdetail' 'nkill'\n",
            " 'nkillus' 'nkillter' 'nwound' 'nwoundus' 'nwoundte' 'property'\n",
            " 'propextent' 'propextent_txt' 'propvalue' 'propcomment' 'ishostkid'\n",
            " 'nhostkid' 'nhostkidus' 'nhours' 'ndays' 'divert' 'kidhijcountry'\n",
            " 'ransom' 'ransomamt' 'ransomamtus' 'ransompaid' 'ransompaidus'\n",
            " 'ransomnote' 'hostkidoutcome' 'hostkidoutcome_txt' 'nreleased' 'addnotes'\n",
            " 'scite1' 'scite2' 'scite3' 'dbsource' 'INT_LOG' 'INT_IDEO' 'INT_MISC'\n",
            " 'INT_ANY' 'related']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_29KRCKqrj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gtd_filtered_df = gtd_df[['country','country_txt','region','region_txt','city','provstate', 'targtype1','targtype1_txt', 'iyear','imonth', 'gname', 'weaptype1', 'weaptype1_txt','attacktype1_txt','attacktype1']]\n",
        "# gtd_filtered_df = gtd_filtered_df.rename(index=str, columns={\"city\": \"city_txt\", \"provstate\": \"provstate_txt\", \"gname\": \"gname_txt\"})\n",
        "# print(gtd_filtered_df)\n",
        "# print(gtd_filtered_df.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVn6I7Y7OA9F",
        "colab_type": "text"
      },
      "source": [
        "## **GECON Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6AAaOVhHY6z",
        "colab_type": "code",
        "outputId": "5a96417c-e48f-49d0-8eef-2bda455e7023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "gecon_df = pd.read_csv(os.path.join(datadir, 'Gecon40_post_final_kh.csv'),encoding='latin-1')\n",
        "# print(gecon_df.columns.values)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (16,19,25,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lg-yXecp267",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gecon_filtered_df = gecon_df[['AREA', 'COUNTRY', 'DIS_LAKE','DIS_MAJOR_RIVER']]\n",
        "\n",
        "# print(gecon_filtered_df.isna().sum())\n",
        "\n",
        "# print(gecon_filtered_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyO2aL4SObqB",
        "colab_type": "text"
      },
      "source": [
        "## **GeoEPR Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II-_vH73OLvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_df = pd.read_csv(os.path.join(datadir, 'GeoEPR-2018.1.csv'),encoding='latin-1')\n",
        "# print(geo_df.columns.values)\n",
        "# # statename, group\n",
        "# print(geo_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGPkxd05olZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_filtered_df = geo_df[['statename','group']]\n",
        "geo_filtered_df = geo_filtered_df.rename(index=str, columns={\"statename\": \"country_txt\"})\n",
        "# print(geo_filtered_df)\n",
        "# print(geo_filtered_df.isna().sum())\n",
        "# print(geo_filtered_df.groupby('country_txt').count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR7YsgSLVroa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean NaN\n",
        "# geo_filtered_df = geo_filtered_df.fillna(geo_filtered_df.mean())\n",
        "# attributes_NaN = ['statename', 'group', 'type']\n",
        "# geo_filtered_df = remove_NaN(geo_filtered_df, attributes_NaN)\n",
        "\n",
        "# print(geo_filtered_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HVbOmnWVUN1",
        "colab_type": "text"
      },
      "source": [
        "## **Happiness World Report Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yf0iEK_Qh-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "happy_df_17 = pd.read_csv(os.path.join(datadir, 'Happiness2017.csv'),encoding='latin-1')\n",
        "happy_df_16 = pd.read_csv(os.path.join(datadir, 'Happiness2016.csv'),encoding='latin-1')\n",
        "happy_df_15 = pd.read_csv(os.path.join(datadir, 'Happiness2015.csv'),encoding='latin-1')\n",
        "# happiness = [happy_df_15, happy_df_16, happy_df_17]\n",
        "happy_df_17 = happy_df_17.rename(index=str, columns={\"Country\": \"country_txt\", \"Happiness.Rank\": \"Happiness.Rank17\", \"Happiness.Score\": \"Happiness.Score17\", \"Freedom\": \"Freedom17\", \"Economy..GDP.per.Capita.\": \"Economy17\"})\n",
        "happy_df_16 = happy_df_16.rename(index=str, columns={\"Country\": \"country_txt\", \"Happiness Rank\": \"Happiness.Rank16\", \"Happiness Score\": \"Happiness.Score16\", \"Freedom\": \"Freedom16\", \"Economy (GDP per Capita)\": \"Economy16\"})\n",
        "happy_df_15 = happy_df_15.rename(index=str, columns={\"Country\": \"country_txt\", \"Happiness Rank\": \"Happiness.Rank15\", \"Happiness Score\": \"Happiness.Score15\", \"Freedom\": \"Freedom15\", \"Economy (GDP per Capita)\": \"Economy15\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBwAL3P582XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "happiness_filtered = [happy_df_15[['country_txt','Happiness.Score15', 'Freedom15', 'Economy15']],\n",
        "                      happy_df_16[['country_txt','Happiness.Score16', 'Freedom16', 'Economy16']], \n",
        "                      happy_df_17[['country_txt','Happiness.Score17', 'Freedom17', 'Economy17']]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4rbBLk3_hkq",
        "colab_type": "text"
      },
      "source": [
        "###TRIALS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUerAkcwHScA",
        "colab_type": "code",
        "outputId": "bba51358-06ae-4920-895e-1e374ed938cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "d = {'one': pd.Series([1., 3.], index=['a', 'c']), 'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd']), 'three': pd.Series([\"A\", \"B\", \"A\"], index=['a', 'c', 'd'])}\n",
        "df = pd.DataFrame(d)\n",
        "# print(df.isna().sum())\n",
        "# print(df)\n",
        "df = df.dropna()\n",
        "print(df)\n",
        "print(df.shape)\n",
        "d2 = {'four': pd.Series([10., 30.], index=['a', 'c']), 'five': pd.Series([100., 200., 300., 400.], index=['a', 'b', 'c', 'd']), 'six': pd.Series([\"A\", \"B\", \"A\"], index=['a', 'c', 'd'])}\n",
        "df2 = pd.DataFrame(d2)\n",
        "df2 = df2.dropna()\n",
        "print(df2)\n",
        "print(df2.shape)\n",
        "df3 = pd.concat([df, df2], axis = 1)\n",
        "print(df3)\n",
        "print(df3.shape)\n",
        "\n",
        "# print(df.isna().sum())\n",
        "# df = df.fillna(df.mean())\n",
        "# mode =  df['three'].mode()[0]\n",
        "# df['three'] = df.groupby('three')['three'].apply(lambda x: x.fillna(x.value_counts().idxmax() if x.value_counts().max() >=1 else mode , inplace = False))\n",
        "# df['three']= df['three'].fillna(df['three'].value_counts().idxmax())\n",
        "# print(df)\n",
        "# df = pd.DataFrame(data={'location': [1, 2, 3],\n",
        "#                         'coor': [(14.48847, 103.161477),\n",
        "#                               (14.970084, 103.062853),\n",
        "#                               (np.nan, np.nan)]})\n",
        "# print(df)\n",
        "# df.dropna(how='any')\n",
        "# df = df[~df.coor.apply(lambda x: np.isnan(x[0]) & np.isnan(x[1]))]\n",
        "# df = df[pd.DataFrame(df.coor.tolist()).notna().all(1)]\n",
        "# print(df)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   one  two three\n",
            "a  1.0  1.0     A\n",
            "c  3.0  3.0     B\n",
            "(2, 3)\n",
            "   four   five six\n",
            "a  10.0  100.0   A\n",
            "c  30.0  300.0   B\n",
            "(2, 3)\n",
            "   one  two three  four   five six\n",
            "a  1.0  1.0     A  10.0  100.0   A\n",
            "c  3.0  3.0     B  30.0  300.0   B\n",
            "(2, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvSBiTqp3AGr",
        "colab_type": "text"
      },
      "source": [
        "## MERGED DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZFICVLTqH63",
        "colab_type": "text"
      },
      "source": [
        "### Merging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaBxFPRhCOEk",
        "colab_type": "code",
        "outputId": "b785f09d-c0d2-4423-8810-ad6e2d7981b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ethnic_count = geo_filtered_df.groupby('country_txt').count()\n",
        "countries = pd.DataFrame(geo_filtered_df['country_txt'].drop_duplicates().sort_values())\n",
        "ethnic_count = pd.concat([ethnic_count.reset_index(drop=True),countries.reset_index(drop=True)], axis=1)\n",
        "ethnic_count = ethnic_count.rename(index=str, columns={\"group\":\"group_count\"})\n",
        "print(ethnic_count.columns.values)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['group_count' 'country_txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bb158uoK2vo",
        "colab_type": "code",
        "outputId": "1371493e-f4f3-4f47-bed5-e19e84cc9811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# result = pd.concat([gtd_filtered_df, happy_filtered_df],gtd_filtered_df[\"country_txt\"]=happy_filtered_df[\"Country\"])\n",
        "# 'Happiness.Rank' 'Happiness.Score'\n",
        "gtd_merged_happiness = gtd_filtered_df\n",
        "for i in range(len(happiness_filtered)):\n",
        "  gtd_merged_happiness = pd.merge(gtd_merged_happiness, happiness_filtered[i],on='country_txt')\n",
        "gtd_merged_happiness = pd.merge(gtd_merged_happiness, ethnic_count, on='country_txt')\n",
        "print(gtd_merged_happiness.shape)\n",
        "# print(gtd_merged_happiness['region_txt'].drop_duplicates())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(167161, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvaLOvx0AW-T",
        "colab_type": "code",
        "outputId": "22b345db-4010-4598-eaff-1482d72ef6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(gtd_merged_happiness.columns.values)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['country' 'country_txt' 'region' 'region_txt' 'city' 'provstate'\n",
            " 'targtype1' 'targtype1_txt' 'iyear' 'imonth' 'gname' 'weaptype1'\n",
            " 'weaptype1_txt' 'attacktype1_txt' 'attacktype1' 'Happiness.Score15'\n",
            " 'Freedom15' 'Economy15' 'Happiness.Score16' 'Freedom16' 'Economy16'\n",
            " 'Happiness.Score17' 'Freedom17' 'Economy17' 'group_count']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SrJ5XoF1Hwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MENA stands for Middle East and North Africa region\n",
        "mena = gtd_merged_happiness.loc[gtd_merged_happiness['region_txt'] == 'Middle East & North Africa']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Zz5qvuwh3K",
        "colab_type": "code",
        "outputId": "47fcdc9a-acce-45f4-fb7e-71bbc2bb965d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(mena.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qepbd9FCuls2",
        "colab_type": "code",
        "outputId": "10138d6d-f80c-474b-ff73-be8bf71320db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(mena['country_txt'].drop_duplicates())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16236           Jordan\n",
            "19871            Egypt\n",
            "23165          Lebanon\n",
            "25643           Turkey\n",
            "30049             Iran\n",
            "61678           Israel\n",
            "64027           Kuwait\n",
            "78871          Algeria\n",
            "91750          Morocco\n",
            "114426           Syria\n",
            "119326            Iraq\n",
            "153137    Saudi Arabia\n",
            "154671         Bahrain\n",
            "157616           Yemen\n",
            "Name: country_txt, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwzz60lmGGS9",
        "colab_type": "code",
        "outputId": "80088cf1-02a6-4ea6-f891-f363c10d4ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Number of distinct terrorist groups in the MENA region = 636\n",
        "# print(np.unique(mena[['gname']].values))\n",
        "print(np.unique(mena[['gname']]).size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zel0gtDSwGzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# attribute \"Unknown > 27000\" I think we should drop all of that\n",
        "# It doesn't make sense to predict an \"Unknown\"\n",
        "# print(mena['gname'].value_counts())\n",
        "# print(mena['gname'].size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSoCKd-DVHRa",
        "colab_type": "text"
      },
      "source": [
        "### Filtering MENA Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlFLIqIyTpCa",
        "colab_type": "code",
        "outputId": "8a9b2b42-33ac-41cb-9ac7-019d22bdff8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# drop rows with nan in mena\n",
        "print(mena.shape)\n",
        "mena_cleaned = mena.dropna()\n",
        "print(mena_cleaned.shape)\n",
        "\n",
        "# select desired labels\n",
        "mena_filtered = mena_cleaned[(mena_cleaned['gname'] == \"Islamic State of Iraq and the Levant (ISIL)\") | (mena_cleaned['gname'] == \"Kurdistan Workers' Party (PKK)\") | (mena_cleaned['gname'] == \"Houthi extremists (Ansar Allah)\") | (mena_cleaned['gname'] == \"Al-Qaida in the Arabian Peninsula (AQAP)\") | (mena_cleaned['gname'] == \"Al-Qaida in Iraq\")]\n",
        "\n",
        "print(mena_filtered['gname'].value_counts())\n",
        "print(mena_filtered['gname'].size)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 25)\n",
            "(45760, 25)\n",
            "Islamic State of Iraq and the Levant (ISIL)    5553\n",
            "Kurdistan Workers' Party (PKK)                 2137\n",
            "Houthi extremists (Ansar Allah)                1062\n",
            "Al-Qaida in the Arabian Peninsula (AQAP)       1016\n",
            "Al-Qaida in Iraq                                636\n",
            "Name: gname, dtype: int64\n",
            "10404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pS_4ZQ_hfZu",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HOCMeqGjHMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels = np.unique(mena_filtered[['gname']])\n",
        "# labels = pd.DataFrame(labels)\n",
        "# print(labels)\n",
        "# print(type(labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtw5FW9gnbjH",
        "colab_type": "code",
        "outputId": "ef35f1f1-4bf3-4701-c54b-2a5ba0d1731d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7004
        }
      },
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "string_attributes = ['city', 'provstate', 'gname']\n",
        "mena_final = mena_filtered\n",
        "mena_final = mena_final.drop([\"gname\", \"provstate\", \"city\"], axis=1)\n",
        "print(mena_final.shape)\n",
        "print(mena_final.columns)\n",
        "\n",
        "for i in range(len(string_attributes)):\n",
        "  attribute_name = string_attributes[i]\n",
        "  attribute_list = mena_filtered[attribute_name]\n",
        "  attribute_encoded = label_encoder.fit_transform(attribute_list)\n",
        "  value_zipped_encoded_list = list(zip(attribute_list,attribute_encoded))\n",
        "  value_zipped_encoded_df = pd.DataFrame(value_zipped_encoded_list)\n",
        "  modified_attribute_name = attribute_name + '_numerical'\n",
        "  value_zipped_encoded_df.columns = [attribute_name, modified_attribute_name]\n",
        "  zipped_df = pd.DataFrame(value_zipped_encoded_df)\n",
        "  print(zipped_df.shape)\n",
        "  print(mena_final.shape)\n",
        "  mena_final.reset_index(drop=True, inplace=True)\n",
        "  zipped_df.reset_index(drop=True, inplace=True)\n",
        "  mena_final = pd.concat([mena_final, zipped_df], axis = 1)\n",
        "  print(\"after concat\")\n",
        "  print(mena_final.shape)\n",
        "  print(\"*************\")\n",
        "\n",
        "print(mena_final.shape) \n",
        "# print(mena_final.isna().sum())\n",
        "mena_final = mena_final.dropna()\n",
        "print(mena_final.shape)\n",
        "print(mena_final.columns)\n",
        "# zipped_df = pd.DataFrame(value_zipped_encoded_df)\n",
        "# mena_final = pd.concat([zipped_df, mena_filtered], axis = 1)\n",
        "# print(zipped_df.columns.values)\n",
        "print(mena_final)\n",
        "# print(mena_final.columns.values)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10404, 22)\n",
            "Index(['country', 'country_txt', 'region', 'region_txt', 'targtype1',\n",
            "       'targtype1_txt', 'iyear', 'imonth', 'weaptype1', 'weaptype1_txt',\n",
            "       'attacktype1_txt', 'attacktype1', 'Happiness.Score15', 'Freedom15',\n",
            "       'Economy15', 'Happiness.Score16', 'Freedom16', 'Economy16',\n",
            "       'Happiness.Score17', 'Freedom17', 'Economy17', 'group_count'],\n",
            "      dtype='object')\n",
            "(10404, 2)\n",
            "(10404, 22)\n",
            "after concat\n",
            "(10404, 24)\n",
            "*************\n",
            "(10404, 2)\n",
            "(10404, 24)\n",
            "after concat\n",
            "(10404, 26)\n",
            "*************\n",
            "(10404, 2)\n",
            "(10404, 26)\n",
            "after concat\n",
            "(10404, 28)\n",
            "*************\n",
            "(10404, 28)\n",
            "(10404, 28)\n",
            "Index(['country', 'country_txt', 'region', 'region_txt', 'targtype1',\n",
            "       'targtype1_txt', 'iyear', 'imonth', 'weaptype1', 'weaptype1_txt',\n",
            "       'attacktype1_txt', 'attacktype1', 'Happiness.Score15', 'Freedom15',\n",
            "       'Economy15', 'Happiness.Score16', 'Freedom16', 'Economy16',\n",
            "       'Happiness.Score17', 'Freedom17', 'Economy17', 'group_count', 'city',\n",
            "       'city_numerical', 'provstate', 'provstate_numerical', 'gname',\n",
            "       'gname_numerical'],\n",
            "      dtype='object')\n",
            "       country country_txt  region                  region_txt  targtype1  \\\n",
            "0          102      Jordan      10  Middle East & North Africa          1   \n",
            "1          102      Jordan      10  Middle East & North Africa          1   \n",
            "2          102      Jordan      10  Middle East & North Africa          1   \n",
            "3          102      Jordan      10  Middle East & North Africa          3   \n",
            "4          102      Jordan      10  Middle East & North Africa          4   \n",
            "5          102      Jordan      10  Middle East & North Africa         17   \n",
            "6          102      Jordan      10  Middle East & North Africa          3   \n",
            "7          102      Jordan      10  Middle East & North Africa          3   \n",
            "8          102      Jordan      10  Middle East & North Africa         18   \n",
            "9           60       Egypt      10  Middle East & North Africa          3   \n",
            "10          60       Egypt      10  Middle East & North Africa          3   \n",
            "11          60       Egypt      10  Middle East & North Africa          3   \n",
            "12         110     Lebanon      10  Middle East & North Africa         14   \n",
            "13         110     Lebanon      10  Middle East & North Africa         17   \n",
            "14         110     Lebanon      10  Middle East & North Africa         17   \n",
            "15         110     Lebanon      10  Middle East & North Africa         17   \n",
            "16         110     Lebanon      10  Middle East & North Africa         17   \n",
            "17         110     Lebanon      10  Middle East & North Africa         15   \n",
            "18         110     Lebanon      10  Middle East & North Africa         14   \n",
            "19         110     Lebanon      10  Middle East & North Africa         14   \n",
            "20         110     Lebanon      10  Middle East & North Africa         17   \n",
            "21         110     Lebanon      10  Middle East & North Africa         17   \n",
            "22         110     Lebanon      10  Middle East & North Africa         14   \n",
            "23         110     Lebanon      10  Middle East & North Africa         14   \n",
            "24         110     Lebanon      10  Middle East & North Africa         14   \n",
            "25         110     Lebanon      10  Middle East & North Africa          3   \n",
            "26         110     Lebanon      10  Middle East & North Africa          4   \n",
            "27         110     Lebanon      10  Middle East & North Africa          1   \n",
            "28         110     Lebanon      10  Middle East & North Africa          1   \n",
            "29         110     Lebanon      10  Middle East & North Africa          1   \n",
            "...        ...         ...     ...                         ...        ...   \n",
            "10374      228       Yemen      10  Middle East & North Africa          4   \n",
            "10375      228       Yemen      10  Middle East & North Africa         17   \n",
            "10376      228       Yemen      10  Middle East & North Africa          4   \n",
            "10377      228       Yemen      10  Middle East & North Africa          4   \n",
            "10378      228       Yemen      10  Middle East & North Africa          4   \n",
            "10379      228       Yemen      10  Middle East & North Africa         17   \n",
            "10380      228       Yemen      10  Middle East & North Africa          2   \n",
            "10381      228       Yemen      10  Middle East & North Africa          2   \n",
            "10382      228       Yemen      10  Middle East & North Africa          4   \n",
            "10383      228       Yemen      10  Middle East & North Africa         17   \n",
            "10384      228       Yemen      10  Middle East & North Africa          2   \n",
            "10385      228       Yemen      10  Middle East & North Africa          2   \n",
            "10386      228       Yemen      10  Middle East & North Africa         14   \n",
            "10387      228       Yemen      10  Middle East & North Africa          2   \n",
            "10388      228       Yemen      10  Middle East & North Africa         10   \n",
            "10389      228       Yemen      10  Middle East & North Africa         14   \n",
            "10390      228       Yemen      10  Middle East & North Africa         14   \n",
            "10391      228       Yemen      10  Middle East & North Africa          2   \n",
            "10392      228       Yemen      10  Middle East & North Africa          2   \n",
            "10393      228       Yemen      10  Middle East & North Africa         14   \n",
            "10394      228       Yemen      10  Middle East & North Africa          2   \n",
            "10395      228       Yemen      10  Middle East & North Africa         14   \n",
            "10396      228       Yemen      10  Middle East & North Africa          4   \n",
            "10397      228       Yemen      10  Middle East & North Africa         14   \n",
            "10398      228       Yemen      10  Middle East & North Africa         10   \n",
            "10399      228       Yemen      10  Middle East & North Africa         14   \n",
            "10400      228       Yemen      10  Middle East & North Africa         14   \n",
            "10401      228       Yemen      10  Middle East & North Africa         14   \n",
            "10402      228       Yemen      10  Middle East & North Africa         14   \n",
            "10403      228       Yemen      10  Middle East & North Africa          4   \n",
            "\n",
            "                        targtype1_txt  iyear  imonth  weaptype1 weaptype1_txt  \\\n",
            "0                            Business   2005      11          6    Explosives   \n",
            "1                            Business   2005      11          6    Explosives   \n",
            "2                            Business   2005      11          6    Explosives   \n",
            "3                              Police   2015      11          5      Firearms   \n",
            "4                            Military   2016       6          6    Explosives   \n",
            "5        Terrorists/Non-State Militia   2016      10          6    Explosives   \n",
            "6                              Police   2016      12          5      Firearms   \n",
            "7                              Police   2016      12          5      Firearms   \n",
            "8                            Tourists   2016      12          6    Explosives   \n",
            "9                              Police   2014       8          5      Firearms   \n",
            "10                             Police   2014       8          5      Firearms   \n",
            "11                             Police   2014       8          5      Firearms   \n",
            "12        Private Citizens & Property   2014       1          6    Explosives   \n",
            "13       Terrorists/Non-State Militia   2014       1          6    Explosives   \n",
            "14       Terrorists/Non-State Militia   2014       1          6    Explosives   \n",
            "15       Terrorists/Non-State Militia   2014       1          6    Explosives   \n",
            "16       Terrorists/Non-State Militia   2014       1          6    Explosives   \n",
            "17     Religious Figures/Institutions   2014       1          6    Explosives   \n",
            "18        Private Citizens & Property   2014       2          6    Explosives   \n",
            "19        Private Citizens & Property   2014       3          6    Explosives   \n",
            "20       Terrorists/Non-State Militia   2014       3          6    Explosives   \n",
            "21       Terrorists/Non-State Militia   2014       3          6    Explosives   \n",
            "22        Private Citizens & Property   2014       3          6    Explosives   \n",
            "23        Private Citizens & Property   2014       3          6    Explosives   \n",
            "24        Private Citizens & Property   2014       3          6    Explosives   \n",
            "25                             Police   2014       8          5      Firearms   \n",
            "26                           Military   2014       8          5      Firearms   \n",
            "27                           Business   2014       9         13       Unknown   \n",
            "28                           Business   2014       9         13       Unknown   \n",
            "29                           Business   2014       9         13       Unknown   \n",
            "...                               ...    ...     ...        ...           ...   \n",
            "10374                        Military   2017      11         13       Unknown   \n",
            "10375    Terrorists/Non-State Militia   2017      11          5      Firearms   \n",
            "10376                        Military   2017      11         13       Unknown   \n",
            "10377                        Military   2017      11         13       Unknown   \n",
            "10378                        Military   2017      11         13       Unknown   \n",
            "10379    Terrorists/Non-State Militia   2017      11         13       Unknown   \n",
            "10380            Government (General)   2017      11         13       Unknown   \n",
            "10381            Government (General)   2017      11          5      Firearms   \n",
            "10382                        Military   2017      11          6    Explosives   \n",
            "10383    Terrorists/Non-State Militia   2017      11          5      Firearms   \n",
            "10384            Government (General)   2017      11          5      Firearms   \n",
            "10385            Government (General)   2017      11         13       Unknown   \n",
            "10386     Private Citizens & Property   2017      12         13       Unknown   \n",
            "10387            Government (General)   2017      12          6    Explosives   \n",
            "10388             Journalists & Media   2017      12          6    Explosives   \n",
            "10389     Private Citizens & Property   2017      12          5      Firearms   \n",
            "10390     Private Citizens & Property   2017      12          6    Explosives   \n",
            "10391            Government (General)   2017      12          6    Explosives   \n",
            "10392            Government (General)   2017      12          6    Explosives   \n",
            "10393     Private Citizens & Property   2017      12          5      Firearms   \n",
            "10394            Government (General)   2017      12         13       Unknown   \n",
            "10395     Private Citizens & Property   2017      12          6    Explosives   \n",
            "10396                        Military   2017      12          6    Explosives   \n",
            "10397     Private Citizens & Property   2017      12          6    Explosives   \n",
            "10398             Journalists & Media   2017      12         13       Unknown   \n",
            "10399     Private Citizens & Property   2017      12          6    Explosives   \n",
            "10400     Private Citizens & Property   2017      12          6    Explosives   \n",
            "10401     Private Citizens & Property   2017      12         13       Unknown   \n",
            "10402     Private Citizens & Property   2017      12         13       Unknown   \n",
            "10403                        Military   2017      12          6    Explosives   \n",
            "\n",
            "       ... Happiness.Score17  Freedom17  Economy17  group_count  \\\n",
            "0      ...             5.336   0.418421   0.991012            3   \n",
            "1      ...             5.336   0.418421   0.991012            3   \n",
            "2      ...             5.336   0.418421   0.991012            3   \n",
            "3      ...             5.336   0.418421   0.991012            3   \n",
            "4      ...             5.336   0.418421   0.991012            3   \n",
            "5      ...             5.336   0.418421   0.991012            3   \n",
            "6      ...             5.336   0.418421   0.991012            3   \n",
            "7      ...             5.336   0.418421   0.991012            3   \n",
            "8      ...             5.336   0.418421   0.991012            3   \n",
            "9      ...             4.735   0.282110   0.989702           11   \n",
            "10     ...             4.735   0.282110   0.989702           11   \n",
            "11     ...             4.735   0.282110   0.989702           11   \n",
            "12     ...             5.225   0.288516   1.074988           19   \n",
            "13     ...             5.225   0.288516   1.074988           19   \n",
            "14     ...             5.225   0.288516   1.074988           19   \n",
            "15     ...             5.225   0.288516   1.074988           19   \n",
            "16     ...             5.225   0.288516   1.074988           19   \n",
            "17     ...             5.225   0.288516   1.074988           19   \n",
            "18     ...             5.225   0.288516   1.074988           19   \n",
            "19     ...             5.225   0.288516   1.074988           19   \n",
            "20     ...             5.225   0.288516   1.074988           19   \n",
            "21     ...             5.225   0.288516   1.074988           19   \n",
            "22     ...             5.225   0.288516   1.074988           19   \n",
            "23     ...             5.225   0.288516   1.074988           19   \n",
            "24     ...             5.225   0.288516   1.074988           19   \n",
            "25     ...             5.225   0.288516   1.074988           19   \n",
            "26     ...             5.225   0.288516   1.074988           19   \n",
            "27     ...             5.225   0.288516   1.074988           19   \n",
            "28     ...             5.225   0.288516   1.074988           19   \n",
            "29     ...             5.225   0.288516   1.074988           19   \n",
            "...    ...               ...        ...        ...          ...   \n",
            "10374  ...             3.593   0.249464   0.591683           17   \n",
            "10375  ...             3.593   0.249464   0.591683           17   \n",
            "10376  ...             3.593   0.249464   0.591683           17   \n",
            "10377  ...             3.593   0.249464   0.591683           17   \n",
            "10378  ...             3.593   0.249464   0.591683           17   \n",
            "10379  ...             3.593   0.249464   0.591683           17   \n",
            "10380  ...             3.593   0.249464   0.591683           17   \n",
            "10381  ...             3.593   0.249464   0.591683           17   \n",
            "10382  ...             3.593   0.249464   0.591683           17   \n",
            "10383  ...             3.593   0.249464   0.591683           17   \n",
            "10384  ...             3.593   0.249464   0.591683           17   \n",
            "10385  ...             3.593   0.249464   0.591683           17   \n",
            "10386  ...             3.593   0.249464   0.591683           17   \n",
            "10387  ...             3.593   0.249464   0.591683           17   \n",
            "10388  ...             3.593   0.249464   0.591683           17   \n",
            "10389  ...             3.593   0.249464   0.591683           17   \n",
            "10390  ...             3.593   0.249464   0.591683           17   \n",
            "10391  ...             3.593   0.249464   0.591683           17   \n",
            "10392  ...             3.593   0.249464   0.591683           17   \n",
            "10393  ...             3.593   0.249464   0.591683           17   \n",
            "10394  ...             3.593   0.249464   0.591683           17   \n",
            "10395  ...             3.593   0.249464   0.591683           17   \n",
            "10396  ...             3.593   0.249464   0.591683           17   \n",
            "10397  ...             3.593   0.249464   0.591683           17   \n",
            "10398  ...             3.593   0.249464   0.591683           17   \n",
            "10399  ...             3.593   0.249464   0.591683           17   \n",
            "10400  ...             3.593   0.249464   0.591683           17   \n",
            "10401  ...             3.593   0.249464   0.591683           17   \n",
            "10402  ...             3.593   0.249464   0.591683           17   \n",
            "10403  ...             3.593   0.249464   0.591683           17   \n",
            "\n",
            "                          city  city_numerical         provstate  \\\n",
            "0                        Amman             307             Amman   \n",
            "1                        Amman             307             Amman   \n",
            "2                        Amman             307             Amman   \n",
            "3                     Muwaqqar            1415             Amman   \n",
            "4        Ar-Ruwayshid district             335            Mafraq   \n",
            "5                       Rukban            1576            Mafraq   \n",
            "6                     Qatraneh            1524             Karak   \n",
            "7                        Karak            1097             Karak   \n",
            "8                        Karak            1097             Karak   \n",
            "9                     El-Dabaa             738            Matruh   \n",
            "10                    El-Dabaa             738            Matruh   \n",
            "11                   As Santah             371           Gharbia   \n",
            "12                 Haret Hraik             884     Mount Lebanon   \n",
            "13                       Arsal             362             Beqaa   \n",
            "14                       Arsal             362             Beqaa   \n",
            "15                       Arsal             362             Beqaa   \n",
            "16                       Arsal             362             Beqaa   \n",
            "17                     Baalbek             441             Beqaa   \n",
            "18                      Britel             548             Beqaa   \n",
            "19                      Labweh            1251             Beqaa   \n",
            "20                 Nabi Othman            1418             Beqaa   \n",
            "21                      Labweh            1251             Beqaa   \n",
            "22                 Nabi Othman            1418             Beqaa   \n",
            "23                      Labweh            1251             Beqaa   \n",
            "24                      Labweh            1251             Beqaa   \n",
            "25                       Arsal             362             Beqaa   \n",
            "26                       Arsal             362             Beqaa   \n",
            "27                       Arsal             362             Beqaa   \n",
            "28                       Arsal             362             Beqaa   \n",
            "29                       Arsal             362             Beqaa   \n",
            "...                        ...             ...               ...   \n",
            "10374                   Shaqab            1679             Taizz   \n",
            "10375                 Al-Hutah             140           Shabwah   \n",
            "10376                  Al-Habj             111          Al Bayda   \n",
            "10377                 Al-Jurdi             155          Al Bayda   \n",
            "10378        Az Zahir district             428          Al Bayda   \n",
            "10379         Usaylan district            1890           Shabwah   \n",
            "10380                    Sanaa            1621  Amanat Al Asimah   \n",
            "10381                     Qatn            1522         Hadramawt   \n",
            "10382          Mahfad district            1277             Abyan   \n",
            "10383                     Ataq             411           Shabwah   \n",
            "10384                    Sanaa            1621  Amanat Al Asimah   \n",
            "10385                    Sanaa            1621  Amanat Al Asimah   \n",
            "10386                  Unknown            1883             Saada   \n",
            "10387                    Sanaa            1621  Amanat Al Asimah   \n",
            "10388                    Sanaa            1621  Amanat Al Asimah   \n",
            "10389                    Sanaa            1621  Amanat Al Asimah   \n",
            "10390                    Sanaa            1621  Amanat Al Asimah   \n",
            "10391                    Sanaa            1621  Amanat Al Asimah   \n",
            "10392                    Sanaa            1621  Amanat Al Asimah   \n",
            "10393                    Sanaa            1621  Amanat Al Asimah   \n",
            "10394                    Sanaa            1621  Amanat Al Asimah   \n",
            "10395              Al-Khawkhah             163       Al Hudaydah   \n",
            "10396           Mukha district            1388             Taizz   \n",
            "10397                    Sanaa            1621  Amanat Al Asimah   \n",
            "10398                  Unknown            1883            Dhamar   \n",
            "10399        Khawkhah district            1172       Al Hudaydah   \n",
            "10400                   Al-Ayn              88             Taizz   \n",
            "10401                 Hudaydah             955       Al Hudaydah   \n",
            "10402  Bayt al-Faqiah district             505       Al Hudaydah   \n",
            "10403                    Marib            1323             Marib   \n",
            "\n",
            "       provstate_numerical                                        gname  \\\n",
            "0                       14                             Al-Qaida in Iraq   \n",
            "1                       14                             Al-Qaida in Iraq   \n",
            "2                       14                             Al-Qaida in Iraq   \n",
            "3                       14  Islamic State of Iraq and the Levant (ISIL)   \n",
            "4                       87  Islamic State of Iraq and the Levant (ISIL)   \n",
            "5                       87  Islamic State of Iraq and the Levant (ISIL)   \n",
            "6                       72  Islamic State of Iraq and the Levant (ISIL)   \n",
            "7                       72  Islamic State of Iraq and the Levant (ISIL)   \n",
            "8                       72  Islamic State of Iraq and the Levant (ISIL)   \n",
            "9                       93  Islamic State of Iraq and the Levant (ISIL)   \n",
            "10                      93  Islamic State of Iraq and the Levant (ISIL)   \n",
            "11                      53  Islamic State of Iraq and the Levant (ISIL)   \n",
            "12                      97  Islamic State of Iraq and the Levant (ISIL)   \n",
            "13                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "14                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "15                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "16                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "17                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "18                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "19                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "20                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "21                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "22                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "23                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "24                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "25                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "26                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "27                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "28                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "29                      32  Islamic State of Iraq and the Levant (ISIL)   \n",
            "...                    ...                                          ...   \n",
            "10374                  128              Houthi extremists (Ansar Allah)   \n",
            "10375                  122     Al-Qaida in the Arabian Peninsula (AQAP)   \n",
            "10376                    7              Houthi extremists (Ansar Allah)   \n",
            "10377                    7              Houthi extremists (Ansar Allah)   \n",
            "10378                    7              Houthi extremists (Ansar Allah)   \n",
            "10379                  122              Houthi extremists (Ansar Allah)   \n",
            "10380                   13              Houthi extremists (Ansar Allah)   \n",
            "10381                   57     Al-Qaida in the Arabian Peninsula (AQAP)   \n",
            "10382                    0     Al-Qaida in the Arabian Peninsula (AQAP)   \n",
            "10383                  122     Al-Qaida in the Arabian Peninsula (AQAP)   \n",
            "10384                   13              Houthi extremists (Ansar Allah)   \n",
            "10385                   13              Houthi extremists (Ansar Allah)   \n",
            "10386                  116              Houthi extremists (Ansar Allah)   \n",
            "10387                   13              Houthi extremists (Ansar Allah)   \n",
            "10388                   13              Houthi extremists (Ansar Allah)   \n",
            "10389                   13              Houthi extremists (Ansar Allah)   \n",
            "10390                   13              Houthi extremists (Ansar Allah)   \n",
            "10391                   13              Houthi extremists (Ansar Allah)   \n",
            "10392                   13              Houthi extremists (Ansar Allah)   \n",
            "10393                   13              Houthi extremists (Ansar Allah)   \n",
            "10394                   13              Houthi extremists (Ansar Allah)   \n",
            "10395                    9              Houthi extremists (Ansar Allah)   \n",
            "10396                  128              Houthi extremists (Ansar Allah)   \n",
            "10397                   13              Houthi extremists (Ansar Allah)   \n",
            "10398                   40              Houthi extremists (Ansar Allah)   \n",
            "10399                    9              Houthi extremists (Ansar Allah)   \n",
            "10400                  128              Houthi extremists (Ansar Allah)   \n",
            "10401                    9              Houthi extremists (Ansar Allah)   \n",
            "10402                    9              Houthi extremists (Ansar Allah)   \n",
            "10403                   92              Houthi extremists (Ansar Allah)   \n",
            "\n",
            "       gname_numerical  \n",
            "0                    0  \n",
            "1                    0  \n",
            "2                    0  \n",
            "3                    3  \n",
            "4                    3  \n",
            "5                    3  \n",
            "6                    3  \n",
            "7                    3  \n",
            "8                    3  \n",
            "9                    3  \n",
            "10                   3  \n",
            "11                   3  \n",
            "12                   3  \n",
            "13                   3  \n",
            "14                   3  \n",
            "15                   3  \n",
            "16                   3  \n",
            "17                   3  \n",
            "18                   3  \n",
            "19                   3  \n",
            "20                   3  \n",
            "21                   3  \n",
            "22                   3  \n",
            "23                   3  \n",
            "24                   3  \n",
            "25                   3  \n",
            "26                   3  \n",
            "27                   3  \n",
            "28                   3  \n",
            "29                   3  \n",
            "...                ...  \n",
            "10374                2  \n",
            "10375                1  \n",
            "10376                2  \n",
            "10377                2  \n",
            "10378                2  \n",
            "10379                2  \n",
            "10380                2  \n",
            "10381                1  \n",
            "10382                1  \n",
            "10383                1  \n",
            "10384                2  \n",
            "10385                2  \n",
            "10386                2  \n",
            "10387                2  \n",
            "10388                2  \n",
            "10389                2  \n",
            "10390                2  \n",
            "10391                2  \n",
            "10392                2  \n",
            "10393                2  \n",
            "10394                2  \n",
            "10395                2  \n",
            "10396                2  \n",
            "10397                2  \n",
            "10398                2  \n",
            "10399                2  \n",
            "10400                2  \n",
            "10401                2  \n",
            "10402                2  \n",
            "10403                2  \n",
            "\n",
            "[10404 rows x 28 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQnvjYcWhl48",
        "colab_type": "text"
      },
      "source": [
        "### Divide Data into Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkJT8zPAqe3x",
        "colab_type": "code",
        "outputId": "781a5858-7313-41e0-b20d-6d3821858551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# divide dataset into train and test\n",
        "mena_classification = mena_final.drop([\"gname\", \"country_txt\", \"region_txt\", \"targtype1_txt\", \"provstate\", \"city\", \"weaptype1_txt\", \"attacktype1_txt\", \"imonth\", \"region\"], axis=1)\n",
        "mena_classification = mena_classification.drop(['Happiness.Score15', 'Freedom15', 'Economy15','Happiness.Score16', 'Freedom16', 'Economy16','Happiness.Score17', 'Freedom17', 'Economy17'], axis=1)\n",
        "\n",
        "mena_classification = mena_classification[mena_classification['iyear'] >= 2000]\n",
        "print(mena_classification.shape)\n",
        "\n",
        "iyear = 2017\n",
        "\n",
        "mena_split_train = mena_classification[mena_classification['iyear'] < iyear]\n",
        "mena_split_test = mena_classification[mena_classification['iyear'] >= iyear]\n",
        "\n",
        "mena_split_train = mena_split_train.drop(\"iyear\", axis = 1)\n",
        "mena_split_test = mena_split_test.drop(\"iyear\", axis = 1)\n",
        "\n",
        "\n",
        "labels_train = mena_split_train['gname_numerical']\n",
        "labels_test = mena_split_test['gname_numerical']\n",
        "\n",
        "data_train = mena_split_train.loc[:, mena_split_train.columns != 'gname_numerical']\n",
        "data_test = mena_split_test.loc[:, mena_split_test.columns != 'gname_numerical']\n",
        "\n",
        "# print(labels)\n",
        "# print(trained_data)\n",
        "\n",
        "# mena_train = trained_data.copy()\n",
        "# mena_test = trained_data.copy()\n",
        "\n",
        "# mena_train = mena_train[mena_train['iyear'] < 2017]\n",
        "# mena_test = mena_test[mena_test['iyear'] >= 2017]\n",
        "\n",
        "print(mena_split_train.shape)\n",
        "print(data_train.columns.values)\n",
        "print(mena_split_test.shape)\n",
        "print(data_test.columns.values)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9490, 8)\n",
            "(7842, 7)\n",
            "['country' 'targtype1' 'weaptype1' 'attacktype1' 'city_numerical'\n",
            " 'provstate_numerical']\n",
            "(1648, 7)\n",
            "['country' 'targtype1' 'weaptype1' 'attacktype1' 'city_numerical'\n",
            " 'provstate_numerical']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4fmc1VMx5wV",
        "colab_type": "code",
        "outputId": "7d93ce83-720b-4f31-fe92-5e1336ac1e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "aa = pd.DataFrame(labels_train)\n",
        "print(np.unique(aa))\n",
        "\n",
        "bb = pd.DataFrame(labels_test)\n",
        "print(np.unique(bb))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjjaZr6yMRGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll = np.array(labels_test)\n",
        "\n",
        "print(type(ll))\n",
        "for i in range(len(ll)):\n",
        "  print(ll[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PwEffIqhsqS",
        "colab_type": "text"
      },
      "source": [
        "###KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pb0uJrawlxs",
        "colab_type": "code",
        "outputId": "11887216-8274-4f07-9346-9b0ba98fef6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4423
        }
      },
      "source": [
        "scaler = StandardScaler()  \n",
        "scaler.fit(data_train)\n",
        "\n",
        "data_train = scaler.transform(data_train)  \n",
        "data_test = scaler.transform(data_test)  \n",
        "\n",
        "acc = 0\n",
        "\n",
        "for i in range(3,1000):\n",
        "\n",
        "  # Create KNN Classifier\n",
        "  knn = KNeighborsClassifier(n_neighbors = i)\n",
        "\n",
        "  # Train the model using the training sets\n",
        "  knn.fit(data_train, labels_train)\n",
        "\n",
        "  # Predict the response for test dataset\n",
        "  y_pred = knn.predict(data_test)\n",
        "\n",
        "  # Model Accuracy, how often is the classifier correct?\n",
        "  curr_acc =  metrics.accuracy_score(labels_test, y_pred)\n",
        "  if curr_acc > acc:\n",
        "    acc = curr_acc\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(confusion_matrix(labels_test[0:in_test], y_pred))  \n",
        "    print(classification_report(labels_test[0:in_test], y_pred))\n",
        "    print(i)\n",
        "    "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7730582524271845\n",
            "[[  0   0   0   0   0]\n",
            " [  0  38   5   1   0]\n",
            " [  0  41 109   8   0]\n",
            " [284  10   4 986   7]\n",
            " [  1   0   0  13 141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.43      0.86      0.57        44\n",
            "           2       0.92      0.69      0.79       158\n",
            "           3       0.98      0.76      0.86      1291\n",
            "           4       0.95      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      1648\n",
            "   macro avg       0.66      0.65      0.63      1648\n",
            "weighted avg       0.96      0.77      0.85      1648\n",
            "\n",
            "3\n",
            "Accuracy: 0.8610436893203883\n",
            "[[   0    0    0    0    0]\n",
            " [   0   40    4    0    0]\n",
            " [   2   32  120    4    0]\n",
            " [ 147   14    6 1117    7]\n",
            " [   1    0    0   12  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.47      0.91      0.62        44\n",
            "           2       0.92      0.76      0.83       158\n",
            "           3       0.99      0.87      0.92      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.67      0.69      0.66      1648\n",
            "weighted avg       0.96      0.86      0.91      1648\n",
            "\n",
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8628640776699029\n",
            "[[   0    0    0    0    0]\n",
            " [   0   38    6    0    0]\n",
            " [   0   37  110   11    0]\n",
            " [ 131    7   14 1132    7]\n",
            " [   1    0    0   12  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.46      0.86      0.60        44\n",
            "           2       0.85      0.70      0.76       158\n",
            "           3       0.98      0.88      0.93      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.65      0.67      0.65      1648\n",
            "weighted avg       0.95      0.86      0.90      1648\n",
            "\n",
            "7\n",
            "Accuracy: 0.8938106796116505\n",
            "[[   0    0    0    0    0]\n",
            " [   0   37    6    1    0]\n",
            " [   0   44  103   11    0]\n",
            " [  74    7   12 1191    7]\n",
            " [   1    0    0   12  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.42      0.84      0.56        44\n",
            "           2       0.85      0.65      0.74       158\n",
            "           3       0.98      0.92      0.95      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.89      0.89      0.89      1648\n",
            "   macro avg       0.64      0.67      0.64      1648\n",
            "weighted avg       0.95      0.89      0.92      1648\n",
            "\n",
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8956310679611651\n",
            "[[   0    0    0    0    0]\n",
            " [   0   39    5    0    0]\n",
            " [   0   42  105   11    0]\n",
            " [  69   18    7 1191    6]\n",
            " [   0    0    0   14  141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.39      0.89      0.55        44\n",
            "           2       0.90      0.66      0.76       158\n",
            "           3       0.98      0.92      0.95      1291\n",
            "           4       0.96      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      1648\n",
            "   macro avg       0.65      0.68      0.64      1648\n",
            "weighted avg       0.95      0.90      0.92      1648\n",
            "\n",
            "11\n",
            "Accuracy: 0.8974514563106796\n",
            "[[   0    0    0    0    0]\n",
            " [   0   39    5    0    0]\n",
            " [   0   40  103   15    0]\n",
            " [  65    8   16 1196    6]\n",
            " [   1    0    0   13  141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.45      0.89      0.60        44\n",
            "           2       0.83      0.65      0.73       158\n",
            "           3       0.98      0.93      0.95      1291\n",
            "           4       0.96      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      1648\n",
            "   macro avg       0.64      0.67      0.64      1648\n",
            "weighted avg       0.95      0.90      0.92      1648\n",
            "\n",
            "18\n",
            "Accuracy: 0.8992718446601942\n",
            "[[   0    0    0    0    0]\n",
            " [   0   40    4    0    0]\n",
            " [   0   38  105   15    0]\n",
            " [  63    9   17 1196    6]\n",
            " [   1    0    0   13  141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.46      0.91      0.61        44\n",
            "           2       0.83      0.66      0.74       158\n",
            "           3       0.98      0.93      0.95      1291\n",
            "           4       0.96      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      1648\n",
            "   macro avg       0.65      0.68      0.65      1648\n",
            "weighted avg       0.95      0.90      0.92      1648\n",
            "\n",
            "19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.899878640776699\n",
            "[[   0    0    0    0    0]\n",
            " [   0   37    7    0    0]\n",
            " [   0   37  107   14    0]\n",
            " [  23   26   34 1202    6]\n",
            " [   1    0    0   17  137]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.37      0.84      0.51        44\n",
            "           2       0.72      0.68      0.70       158\n",
            "           3       0.97      0.93      0.95      1291\n",
            "           4       0.96      0.88      0.92       155\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      1648\n",
            "   macro avg       0.61      0.67      0.62      1648\n",
            "weighted avg       0.93      0.90      0.91      1648\n",
            "\n",
            "47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.904126213592233\n",
            "[[   0    0    0    0    0]\n",
            " [   0   37    7    0    0]\n",
            " [   0   35  109   14    0]\n",
            " [  18   26   34 1207    6]\n",
            " [   1    0    0   17  137]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.38      0.84      0.52        44\n",
            "           2       0.73      0.69      0.71       158\n",
            "           3       0.97      0.93      0.95      1291\n",
            "           4       0.96      0.88      0.92       155\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      1648\n",
            "   macro avg       0.61      0.67      0.62      1648\n",
            "weighted avg       0.93      0.90      0.92      1648\n",
            "\n",
            "49\n",
            "Accuracy: 0.9059466019417476\n",
            "[[   0    0    0    0    0]\n",
            " [   0   37    7    0    0]\n",
            " [   0   35  109   14    0]\n",
            " [  15   26   34 1210    6]\n",
            " [   1    0    0   17  137]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.38      0.84      0.52        44\n",
            "           2       0.73      0.69      0.71       158\n",
            "           3       0.98      0.94      0.96      1291\n",
            "           4       0.96      0.88      0.92       155\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      1648\n",
            "   macro avg       0.61      0.67      0.62      1648\n",
            "weighted avg       0.93      0.91      0.92      1648\n",
            "\n",
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9114077669902912\n",
            "[[   0    0    0    0    0]\n",
            " [   0   36    8    0    0]\n",
            " [   0   31  112   15    0]\n",
            " [   7   20   41 1217    6]\n",
            " [   0    0    0   18  137]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.41      0.82      0.55        44\n",
            "           2       0.70      0.71      0.70       158\n",
            "           3       0.97      0.94      0.96      1291\n",
            "           4       0.96      0.88      0.92       155\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      1648\n",
            "   macro avg       0.61      0.67      0.63      1648\n",
            "weighted avg       0.93      0.91      0.92      1648\n",
            "\n",
            "63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-254baf384ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Predict the response for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Model Accuracy, how often is the classifier correct?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 delayed_query(\n\u001b[1;32m    454\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             )\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH9dHA6XCggw",
        "colab_type": "text"
      },
      "source": [
        "###Nave Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCTZXpe2GFek",
        "colab_type": "code",
        "outputId": "e9ff4dbf-a82c-4ea1-fb2d-2b63015d2c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# clf.fit(X_train[0:index], Y_train\n",
        "index = len(labels_train);\n",
        "in_test = len(labels_test)\n",
        "\n",
        "# Create a  Naive Bayes Classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "clf.fit(data_train[0:index], labels_train[0:index])\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(data_test[0:in_test])\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(labels_test[0:in_test], y_pred))\n",
        "print(confusion_matrix(labels_test[0:in_test], y_pred))  \n",
        "print(classification_report(labels_test[0:in_test], y_pred))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3446601941747573\n",
            "[[  0   0   0   0   0]\n",
            " [  0  41   3   0   0]\n",
            " [  0  77  52  29   0]\n",
            " [817   0  28 347  99]\n",
            " [  7   0  16   4 128]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.35      0.93      0.51        44\n",
            "           2       0.53      0.33      0.40       158\n",
            "           3       0.91      0.27      0.42      1291\n",
            "           4       0.56      0.83      0.67       155\n",
            "\n",
            "   micro avg       0.34      0.34      0.34      1648\n",
            "   macro avg       0.47      0.47      0.40      1648\n",
            "weighted avg       0.83      0.34      0.44      1648\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DewW6hNCqDC",
        "colab_type": "text"
      },
      "source": [
        "### Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DmEYYXO4BUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2893
        },
        "outputId": "57b679b8-8b5c-4cbb-cece-d5c11c66f1f6"
      },
      "source": [
        "acc = 0\n",
        "for i in range(3,1000):\n",
        "  # Create a Gaussian Classifier\n",
        "  clf = RandomForestClassifier(n_estimators = i)\n",
        "\n",
        "  # Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "  clf.fit(data_train, labels_train)    \n",
        "  y_pred=clf.predict(data_test)\n",
        "  \n",
        "  curr_acc =  metrics.accuracy_score(labels_test, y_pred)\n",
        "  if curr_acc > acc:\n",
        "    acc = curr_acc\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(confusion_matrix(labels_test[0:in_test], y_pred))  \n",
        "    print(classification_report(labels_test[0:in_test], y_pred))\n",
        "    print(i)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9205097087378641\n",
            "[[   0    0    0    0    0]\n",
            " [   0   42    2    0    0]\n",
            " [   0   26  128    4    0]\n",
            " [  79    0    0 1206    6]\n",
            " [   0    0    0   14  141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.62      0.95      0.75        44\n",
            "           2       0.98      0.81      0.89       158\n",
            "           3       0.99      0.93      0.96      1291\n",
            "           4       0.96      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.92      0.92      0.92      1648\n",
            "   macro avg       0.71      0.72      0.71      1648\n",
            "weighted avg       0.97      0.92      0.94      1648\n",
            "\n",
            "3\n",
            "Accuracy: 0.9296116504854369\n",
            "[[   0    0    0    0    0]\n",
            " [   0   40    4    0    0]\n",
            " [   0   27  130    1    0]\n",
            " [  63    0    0 1220    8]\n",
            " [   0    0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.60      0.91      0.72        44\n",
            "           2       0.97      0.82      0.89       158\n",
            "           3       0.99      0.95      0.97      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.93      0.93      0.93      1648\n",
            "   macro avg       0.70      0.72      0.70      1648\n",
            "weighted avg       0.97      0.93      0.95      1648\n",
            "\n",
            "5\n",
            "Accuracy: 0.9344660194174758\n",
            "[[   0    0    0    0    0]\n",
            " [   0   41    3    0    0]\n",
            " [   0   24  132    2    0]\n",
            " [  57    0    1 1226    7]\n",
            " [   0    0    0   14  141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.63      0.93      0.75        44\n",
            "           2       0.97      0.84      0.90       158\n",
            "           3       0.99      0.95      0.97      1291\n",
            "           4       0.95      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.93      0.93      0.93      1648\n",
            "   macro avg       0.71      0.73      0.71      1648\n",
            "weighted avg       0.97      0.93      0.95      1648\n",
            "\n",
            "6\n",
            "Accuracy: 0.9356796116504854\n",
            "[[   0    0    0    0    0]\n",
            " [   0   43    1    0    0]\n",
            " [   0   28  128    2    0]\n",
            " [  54    0    0 1230    7]\n",
            " [   0    0    0   14  141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.61      0.98      0.75        44\n",
            "           2       0.99      0.81      0.89       158\n",
            "           3       0.99      0.95      0.97      1291\n",
            "           4       0.95      0.91      0.93       155\n",
            "\n",
            "   micro avg       0.94      0.94      0.94      1648\n",
            "   macro avg       0.71      0.73      0.71      1648\n",
            "weighted avg       0.97      0.94      0.95      1648\n",
            "\n",
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9387135922330098\n",
            "[[   0    0    0    0    0]\n",
            " [   0   42    2    0    0]\n",
            " [   0   32  126    0    0]\n",
            " [  47    0    0 1237    7]\n",
            " [   0    0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.57      0.95      0.71        44\n",
            "           2       0.98      0.80      0.88       158\n",
            "           3       0.99      0.96      0.97      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.94      0.94      0.94      1648\n",
            "   macro avg       0.70      0.73      0.70      1648\n",
            "weighted avg       0.97      0.94      0.95      1648\n",
            "\n",
            "13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.941747572815534\n",
            "[[   0    0    0    0    0]\n",
            " [   0   42    2    0    0]\n",
            " [   0   26  131    1    0]\n",
            " [  48    0    0 1237    6]\n",
            " [   0    0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.62      0.95      0.75        44\n",
            "           2       0.98      0.83      0.90       158\n",
            "           3       0.99      0.96      0.97      1291\n",
            "           4       0.96      0.92      0.94       155\n",
            "\n",
            "   micro avg       0.94      0.94      0.94      1648\n",
            "   macro avg       0.71      0.73      0.71      1648\n",
            "weighted avg       0.98      0.94      0.96      1648\n",
            "\n",
            "17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.945995145631068\n",
            "[[   0    0    0    0    0]\n",
            " [   0   43    1    0    0]\n",
            " [   0   22  132    4    0]\n",
            " [  42    0    0 1242    7]\n",
            " [   0    0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.66      0.98      0.79        44\n",
            "           2       0.99      0.84      0.91       158\n",
            "           3       0.99      0.96      0.97      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      1648\n",
            "   macro avg       0.72      0.74      0.72      1648\n",
            "weighted avg       0.98      0.95      0.96      1648\n",
            "\n",
            "35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-55542fa91a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Train the model using the training sets y_pred=clf.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c_kOOg_C8pv",
        "colab_type": "text"
      },
      "source": [
        "###Decision tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFI0_1-b4u2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "33f7fbbe-57f2-4c22-d268-ce5f660fdaa1"
      },
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf.fit(data_train, labels_train)    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "y_pred=clf.predict(data_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(labels_test, y_pred))\n",
        "print(confusion_matrix(labels_test, y_pred))  \n",
        "print(classification_report(labels_test, y_pred))\n",
        "\n",
        "# CART (Classification and Regression Trees) is very similar to C4.5, \n",
        "# but it differs in that it supports numerical target variables (regression) and does not compute rule sets. \n",
        "# CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.\n",
        "# scikit-learn uses an optimised version of the CART algorithm."
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9089805825242718\n",
            "[[   0    0    0    0    0]\n",
            " [   0   41    3    0    0]\n",
            " [   0   29  129    0    0]\n",
            " [  95    0    0 1189    7]\n",
            " [   1    0    0   15  139]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.59      0.93      0.72        44\n",
            "           2       0.98      0.82      0.89       158\n",
            "           3       0.99      0.92      0.95      1291\n",
            "           4       0.95      0.90      0.92       155\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      1648\n",
            "   macro avg       0.70      0.71      0.70      1648\n",
            "weighted avg       0.97      0.91      0.94      1648\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3K5L1O_DAVT",
        "colab_type": "text"
      },
      "source": [
        "###SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeUpFwtM9Ml0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8f9fe665-c775-4058-cad4-e1572039695f"
      },
      "source": [
        "index = len(labels_train);\n",
        "in_test = len(labels_test);\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel = 'linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(data_train[0:index], labels_train[0:index])\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(data_test[0:in_test])\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(labels_test[0:in_test], y_pred))\n",
        "print(confusion_matrix(labels_test[0:in_test], y_pred))  \n",
        "print(classification_report(labels_test[0:in_test], y_pred))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9326456310679612\n",
            "[[  34   10    0    0]\n",
            " [  52   77   29    0]\n",
            " [   0    0 1284    7]\n",
            " [   0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.77      0.52        44\n",
            "           2       0.89      0.49      0.63       158\n",
            "           3       0.97      0.99      0.98      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.93      0.93      0.93      1648\n",
            "   macro avg       0.80      0.79      0.77      1648\n",
            "weighted avg       0.94      0.93      0.93      1648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}