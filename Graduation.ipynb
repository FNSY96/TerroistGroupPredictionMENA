{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graduation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kPi0no_cHquU",
        "Orw3jIStJs9N",
        "vw3KmVuwLEH3",
        "eesT4I_fLgXq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FNSY96/TerrorismEventsPrediction/blob/master/Graduation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t4_K6rWMxmH",
        "colab_type": "text"
      },
      "source": [
        "# **Python Imports**\n",
        "PLEASE PUT ALL LIBRARY IMPORTS IN THIS CELL **ONLY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4DPSp_3SaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pandas\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SkGUUzMMr4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import glob\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTQAhp_HNvyG",
        "colab_type": "text"
      },
      "source": [
        "# Data Set Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N13I8JpfMHc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "datadir  = 'drive/My Drive/GraduationProject/Data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bYFOOr9U-7h",
        "colab_type": "text"
      },
      "source": [
        "## **GTD Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzPwkdhBZRZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gtd_df = pd.read_csv(os.path.join(datadir, 'gtd.csv'), encoding = 'latin-1')\n",
        "print(gtd_df.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_29KRCKqrj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gtd_filtered_df = gtd_df[['country', 'country_txt','region','region_txt','city','provstate', 'targtype1','targtype1_txt', 'iyear','imonth', 'gname', 'weaptype1', 'weaptype1_txt','attacktype1_txt','attacktype1']]\n",
        "# gtd_filtered_df = gtd_filtered_df.rename(index=str, columns={\"city\": \"city_txt\", \"provstate\": \"provstate_txt\", \"gname\": \"gname_txt\"})\n",
        "# print(gtd_filtered_df)\n",
        "# print(gtd_filtered_df.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVn6I7Y7OA9F",
        "colab_type": "text"
      },
      "source": [
        "## **GECON Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6AAaOVhHY6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gecon_df = pd.read_csv(os.path.join(datadir, 'Gecon40_post_final_kh.csv'),encoding='latin-1')\n",
        "# print(gecon_df.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lg-yXecp267",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gecon_filtered_df = gecon_df[['AREA', 'COUNTRY', 'DIS_LAKE','DIS_MAJOR_RIVER']]\n",
        "\n",
        "# print(gecon_filtered_df.isna().sum())\n",
        "\n",
        "# print(gecon_filtered_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyO2aL4SObqB",
        "colab_type": "text"
      },
      "source": [
        "## **GeoEPR Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II-_vH73OLvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_df = pd.read_csv(os.path.join(datadir, 'GeoEPR-2018.1.csv'),encoding='latin-1')\n",
        "# print(geo_df.columns.values)\n",
        "# # statename, group\n",
        "# print(geo_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGPkxd05olZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_filtered_df = geo_df[['statename','group']]\n",
        "geo_filtered_df = geo_filtered_df.rename(index=str, columns={\"statename\": \"country_txt\"})\n",
        "# print(geo_filtered_df)\n",
        "# print(geo_filtered_df.isna().sum())\n",
        "# print(geo_filtered_df.groupby('country_txt').count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0lc674Y6GQ7",
        "colab_type": "code",
        "outputId": "98d40b99-6ba0-4f52-bfd3-672ebf59f57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ethnic_count = geo_filtered_df.groupby('country_txt').count()\n",
        "countries = pd.DataFrame(geo_filtered_df['country_txt'].drop_duplicates().sort_values())\n",
        "ethnic_count = pd.concat([ethnic_count.reset_index(drop=True),countries.reset_index(drop=True)], axis=1)\n",
        "ethnic_count = ethnic_count.rename(index=str, columns={\"group\":\"group_count\"})\n",
        "print(ethnic_count.columns.values)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['group_count' 'country_txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HVbOmnWVUN1",
        "colab_type": "text"
      },
      "source": [
        "## **Happiness World Report Data Frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yf0iEK_Qh-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "happy_df_17 = pd.read_csv(os.path.join(datadir, 'Happiness2017.csv'),encoding='latin-1')\n",
        "happy_df_16 = pd.read_csv(os.path.join(datadir, 'Happiness2016.csv'),encoding='latin-1')\n",
        "happy_df_15 = pd.read_csv(os.path.join(datadir, 'Happiness2015.csv'),encoding='latin-1')\n",
        "\n",
        "happy_df_17 = happy_df_17.rename(index=str, columns={\"Country\": \"country_txt\", \"Happiness.Rank\": \"Happiness.Rank17\", \"Happiness.Score\": \"Happiness.Score17\", \"Freedom\": \"Freedom17\", \"Economy..GDP.per.Capita.\": \"Economy17\"})\n",
        "happy_df_16 = happy_df_16.rename(index=str, columns={\"Country\": \"country_txt\", \"Happiness Rank\": \"Happiness.Rank16\", \"Happiness Score\": \"Happiness.Score16\", \"Freedom\": \"Freedom16\", \"Economy (GDP per Capita)\": \"Economy16\"})\n",
        "happy_df_15 = happy_df_15.rename(index=str, columns={\"Country\": \"country_txt\", \"Happiness Rank\": \"Happiness.Rank15\", \"Happiness Score\": \"Happiness.Score15\", \"Freedom\": \"Freedom15\", \"Economy (GDP per Capita)\": \"Economy15\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBwAL3P582XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "happiness_filtered = [happy_df_15[['country_txt','Happiness.Score15', 'Freedom15', 'Economy15']],\n",
        "                      happy_df_16[['country_txt','Happiness.Score16', 'Freedom16', 'Economy16']], \n",
        "                      happy_df_17[['country_txt','Happiness.Score17', 'Freedom17', 'Economy17']]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvSBiTqp3AGr",
        "colab_type": "text"
      },
      "source": [
        "# Merging Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bb158uoK2vo",
        "colab_type": "code",
        "outputId": "7bbb5940-6702-4159-fd4f-f233ddf546ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# merging gtd with happiness\n",
        "gtd_merged_happiness = gtd_filtered_df\n",
        "for i in range(len(happiness_filtered)):\n",
        "  gtd_merged_happiness = pd.merge(gtd_merged_happiness, happiness_filtered[i],on='country_txt')\n",
        "print(gtd_merged_happiness.shape)\n",
        "\n",
        "# merging gtd & happiness with ethnic\n",
        "gtd_merged_happiness_ethnic = pd.merge(gtd_merged_happiness, ethnic_count, on='country_txt')\n",
        "print(gtd_merged_happiness_ethnic.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(171630, 24)\n",
            "(167161, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O8BTOIIv-Aoh",
        "outputId": "cba6cbd7-f5aa-4f69-a5dc-fd740f9b861d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# selecting Middle East & North Africa region\n",
        "# MENA stands for Middle East and North Africa region\n",
        "mena = gtd_merged_happiness_ethnic.loc[gtd_merged_happiness_ethnic['region_txt'] == 'Middle East & North Africa']\n",
        "print(mena.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "308ec6fe-27e6-4f1a-fd28-16b2da6aca0d",
        "id": "yt-r1kxa9AfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Number of distinct terrorist groups in the MENA region = 636\n",
        "# print(np.unique(mena[['gname']].values))\n",
        "print(np.unique(mena[['gname']]).size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSoCKd-DVHRa",
        "colab_type": "text"
      },
      "source": [
        "#Creating MENA Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6jB6GYcNHuF",
        "colab_type": "text"
      },
      "source": [
        "### removing nan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlFLIqIyTpCa",
        "colab_type": "code",
        "outputId": "3baa8886-29a5-4caa-9f9c-0c4beffe834f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# drop rows with nan in mena\n",
        "print(mena.shape)\n",
        "mena_cleaned = mena.dropna()\n",
        "print(mena_cleaned.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 25)\n",
            "(45760, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGQiXFEdNP-2",
        "colab_type": "text"
      },
      "source": [
        "###Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO7_eLCPNVGf",
        "colab_type": "code",
        "outputId": "197a300f-0a94-4fb7-d0fb-7dda3189acd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# select desired labels\n",
        "mena_filtered = mena_cleaned[(mena_cleaned['gname'] == \"Islamic State of Iraq and the Levant (ISIL)\") | (mena_cleaned['gname'] == \"Kurdistan Workers' Party (PKK)\") | (mena_cleaned['gname'] == \"Houthi extremists (Ansar Allah)\") | (mena_cleaned['gname'] == \"Al-Qaida in the Arabian Peninsula (AQAP)\") | (mena_cleaned['gname'] == \"Al-Qaida in Iraq\")]\n",
        "\n",
        "print(mena_filtered['gname'].value_counts())\n",
        "print(mena_filtered['gname'].size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Islamic State of Iraq and the Levant (ISIL)    5553\n",
            "Kurdistan Workers' Party (PKK)                 2137\n",
            "Houthi extremists (Ansar Allah)                1062\n",
            "Al-Qaida in the Arabian Peninsula (AQAP)       1016\n",
            "Al-Qaida in Iraq                                636\n",
            "Name: gname, dtype: int64\n",
            "10404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pS_4ZQ_hfZu",
        "colab_type": "text"
      },
      "source": [
        "### Data Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtw5FW9gnbjH",
        "colab_type": "code",
        "outputId": "0e72d845-57b4-447d-9102-9596754dd9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# convert categorical attributes to numerical\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "string_attributes = ['city', 'provstate', 'gname']\n",
        "mena_final = mena_filtered\n",
        "mena_final = mena_final.drop([\"gname\", \"provstate\", \"city\"], axis=1)\n",
        "print(mena_final.shape)\n",
        "print(mena_final.columns)\n",
        "\n",
        "for i in range(len(string_attributes)):\n",
        "  attribute_name = string_attributes[i]\n",
        "  attribute_list = mena_filtered[attribute_name]\n",
        "  attribute_encoded = label_encoder.fit_transform(attribute_list)\n",
        "  value_zipped_encoded_list = list(zip(attribute_list,attribute_encoded))\n",
        "  value_zipped_encoded_df = pd.DataFrame(value_zipped_encoded_list)\n",
        "  modified_attribute_name = attribute_name + '_numerical'\n",
        "  value_zipped_encoded_df.columns = [attribute_name, modified_attribute_name]\n",
        "  zipped_df = pd.DataFrame(value_zipped_encoded_df)\n",
        "  print(zipped_df.shape)\n",
        "  print(mena_final.shape)\n",
        "  mena_final.reset_index(drop=True, inplace=True)\n",
        "  zipped_df.reset_index(drop=True, inplace=True)\n",
        "  mena_final = pd.concat([mena_final, zipped_df], axis = 1)\n",
        "  print(\"after concat\")\n",
        "  print(mena_final.shape)\n",
        "  print(\"*************\")\n",
        "  \n",
        "mena_final = mena_final.dropna()\n",
        "print(mena_final.shape)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10404, 22)\n",
            "Index(['country', 'country_txt', 'region', 'region_txt', 'targtype1',\n",
            "       'targtype1_txt', 'iyear', 'imonth', 'weaptype1', 'weaptype1_txt',\n",
            "       'attacktype1_txt', 'attacktype1', 'Happiness.Score15', 'Freedom15',\n",
            "       'Economy15', 'Happiness.Score16', 'Freedom16', 'Economy16',\n",
            "       'Happiness.Score17', 'Freedom17', 'Economy17', 'group_count'],\n",
            "      dtype='object')\n",
            "(10404, 2)\n",
            "(10404, 22)\n",
            "after concat\n",
            "(10404, 24)\n",
            "*************\n",
            "(10404, 2)\n",
            "(10404, 24)\n",
            "after concat\n",
            "(10404, 26)\n",
            "*************\n",
            "(10404, 2)\n",
            "(10404, 26)\n",
            "after concat\n",
            "(10404, 28)\n",
            "*************\n",
            "(10404, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywwlm8E7NoZZ",
        "colab_type": "text"
      },
      "source": [
        "### removing categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWjYCZX5Ni1-",
        "colab_type": "code",
        "outputId": "536b5713-daeb-4126-c8ec-b69590c03725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mena_final = mena_final.drop([\"gname\", \"country_txt\", \"region_txt\", \"targtype1_txt\", \"provstate\", \"city\", \"weaptype1_txt\", \"attacktype1_txt\", \"imonth\", \"region\"], axis=1)\n",
        "print(mena_final.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10404, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGi0Ts_YOu57",
        "colab_type": "text"
      },
      "source": [
        "###removing records before year 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asho1kRuO5kS",
        "colab_type": "code",
        "outputId": "6decbf23-2bcd-4f7c-b994-ca1d2b97f160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mena_final = mena_final[mena_final['iyear'] >= 2000]\n",
        "print(mena_final.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9490, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQnvjYcWhl48",
        "colab_type": "text"
      },
      "source": [
        "#Divide Data into Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4ybWceOxXTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mena_gtd = mena_final.drop(['Happiness.Score15', 'Freedom15', 'Economy15','Happiness.Score16', 'Freedom16', 'Economy16','Happiness.Score17', 'Freedom17', 'Economy17', 'group_count'], axis=1)\n",
        "mena_gtd_happiness = mena_final.drop(['group_count'], axis=1)\n",
        "mena_gtd_ethnic = mena_final.drop(['Happiness.Score15', 'Freedom15', 'Economy15','Happiness.Score16', 'Freedom16', 'Economy16','Happiness.Score17', 'Freedom17', 'Economy17'], axis=1)\n",
        "mena_gtd_happiness_ethnic = mena_final\n",
        "#print(mena_gtd_happiness_ethnic.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkJT8zPAqe3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# divide dataset into train and test\n",
        "def train_test(mena_classification):\n",
        "  \n",
        "  mena_split_train = mena_classification[mena_classification['iyear'] < 2017]\n",
        "  mena_split_test = mena_classification[mena_classification['iyear'] >= 2017]\n",
        "  \n",
        "  mena_split_train = mena_split_train.drop(\"iyear\", axis = 1)\n",
        "  mena_split_test = mena_split_test.drop(\"iyear\", axis = 1)\n",
        "\n",
        "\n",
        "  labels_train = mena_split_train['gname_numerical']\n",
        "  labels_test = mena_split_test['gname_numerical']\n",
        "  \n",
        "  data_train = mena_split_train.loc[:, mena_split_train.columns != 'gname_numerical']\n",
        "  data_test = mena_split_test.loc[:, mena_split_test.columns != 'gname_numerical']\n",
        "\n",
        "  print(mena_split_train.shape)\n",
        "  print(mena_split_test.shape)\n",
        "\n",
        "\n",
        "  print(labels_train.shape)\n",
        "  print(labels_train.shape)\n",
        "  \n",
        "  return labels_train, labels_test, data_train, data_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LaHEI9eDwwr",
        "colab_type": "code",
        "outputId": "083ea78f-d408-4ade-edd0-7e3e414ef436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4590
        }
      },
      "source": [
        "labels_train1, labels_test1, data_train1, data_test1 = train_test(mena_gtd)\n",
        "labels_train2, labels_test2, data_train2, data_test2 = train_test(mena_gtd_happiness)\n",
        "labels_train3, labels_test3, data_train3, data_test3 = train_test(mena_gtd_ethnic)\n",
        "labels_train4, labels_test4, data_train4, data_test4 = train_test(mena_gtd_happiness_ethnic)\n",
        "\n",
        "print(mena_final)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7842, 7)\n",
            "(1648, 7)\n",
            "(7842,)\n",
            "(7842,)\n",
            "(7842, 16)\n",
            "(1648, 16)\n",
            "(7842,)\n",
            "(7842,)\n",
            "(7842, 8)\n",
            "(1648, 8)\n",
            "(7842,)\n",
            "(7842,)\n",
            "(7842, 17)\n",
            "(1648, 17)\n",
            "(7842,)\n",
            "(7842,)\n",
            "       country  targtype1  iyear  weaptype1  attacktype1  Happiness.Score15  \\\n",
            "0          102          1   2005          6            3              5.192   \n",
            "1          102          1   2005          6            3              5.192   \n",
            "2          102          1   2005          6            3              5.192   \n",
            "3          102          3   2015          5            2              5.192   \n",
            "4          102          4   2016          6            3              5.192   \n",
            "5          102         17   2016          6            3              5.192   \n",
            "6          102          3   2016          5            2              5.192   \n",
            "7          102          3   2016          5            2              5.192   \n",
            "8          102         18   2016          6            5              5.192   \n",
            "9           60          3   2014          5            2              4.194   \n",
            "10          60          3   2014          5            2              4.194   \n",
            "11          60          3   2014          5            2              4.194   \n",
            "12         110         14   2014          6            3              4.839   \n",
            "13         110         17   2014          6            3              4.839   \n",
            "14         110         17   2014          6            3              4.839   \n",
            "15         110         17   2014          6            3              4.839   \n",
            "16         110         17   2014          6            3              4.839   \n",
            "17         110         15   2014          6            3              4.839   \n",
            "18         110         14   2014          6            3              4.839   \n",
            "19         110         14   2014          6            3              4.839   \n",
            "20         110         17   2014          6            3              4.839   \n",
            "21         110         17   2014          6            3              4.839   \n",
            "22         110         14   2014          6            3              4.839   \n",
            "23         110         14   2014          6            3              4.839   \n",
            "24         110         14   2014          6            3              4.839   \n",
            "25         110          3   2014          5            6              4.839   \n",
            "26         110          4   2014          5            2              4.839   \n",
            "27         110          1   2014         13            7              4.839   \n",
            "28         110          1   2014         13            7              4.839   \n",
            "29         110          1   2014         13            7              4.839   \n",
            "...        ...        ...    ...        ...          ...                ...   \n",
            "10374      228          4   2017         13            9              4.077   \n",
            "10375      228         17   2017          5            1              4.077   \n",
            "10376      228          4   2017         13            9              4.077   \n",
            "10377      228          4   2017         13            9              4.077   \n",
            "10378      228          4   2017         13            9              4.077   \n",
            "10379      228         17   2017         13            9              4.077   \n",
            "10380      228          2   2017         13            9              4.077   \n",
            "10381      228          2   2017          5            1              4.077   \n",
            "10382      228          4   2017          6            1              4.077   \n",
            "10383      228         17   2017          5            2              4.077   \n",
            "10384      228          2   2017          5            2              4.077   \n",
            "10385      228          2   2017         13            9              4.077   \n",
            "10386      228         14   2017         13            9              4.077   \n",
            "10387      228          2   2017          6            2              4.077   \n",
            "10388      228         10   2017          6            6              4.077   \n",
            "10389      228         14   2017          5            6              4.077   \n",
            "10390      228         14   2017          6            3              4.077   \n",
            "10391      228          2   2017          6            1              4.077   \n",
            "10392      228          2   2017          6            3              4.077   \n",
            "10393      228         14   2017          5            2              4.077   \n",
            "10394      228          2   2017         13            6              4.077   \n",
            "10395      228         14   2017          6            3              4.077   \n",
            "10396      228          4   2017          6            3              4.077   \n",
            "10397      228         14   2017          6            3              4.077   \n",
            "10398      228         10   2017         13            6              4.077   \n",
            "10399      228         14   2017          6            3              4.077   \n",
            "10400      228         14   2017          6            3              4.077   \n",
            "10401      228         14   2017         13            6              4.077   \n",
            "10402      228         14   2017         13            6              4.077   \n",
            "10403      228          4   2017          6            3              4.077   \n",
            "\n",
            "       Freedom15  Economy15  Happiness.Score16  Freedom16  Economy16  \\\n",
            "0        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "1        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "2        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "3        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "4        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "5        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "6        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "7        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "8        0.40661    0.90198              5.303    0.36023    0.99673   \n",
            "9        0.17288    0.88180              4.362    0.18847    0.95395   \n",
            "10       0.17288    0.88180              4.362    0.18847    0.95395   \n",
            "11       0.17288    0.88180              4.362    0.18847    0.95395   \n",
            "12       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "13       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "14       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "15       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "16       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "17       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "18       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "19       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "20       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "21       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "22       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "23       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "24       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "25       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "26       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "27       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "28       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "29       0.33916    1.02564              5.129    0.26228    1.12268   \n",
            "...          ...        ...                ...        ...        ...   \n",
            "10374    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10375    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10376    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10377    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10378    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10379    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10380    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10381    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10382    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10383    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10384    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10385    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10386    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10387    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10388    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10389    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10390    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10391    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10392    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10393    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10394    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10395    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10396    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10397    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10398    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10399    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10400    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10401    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10402    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "10403    0.35571    0.54649              3.724    0.22870    0.57939   \n",
            "\n",
            "       Happiness.Score17  Freedom17  Economy17  group_count  city_numerical  \\\n",
            "0                  5.336   0.418421   0.991012            3             307   \n",
            "1                  5.336   0.418421   0.991012            3             307   \n",
            "2                  5.336   0.418421   0.991012            3             307   \n",
            "3                  5.336   0.418421   0.991012            3            1415   \n",
            "4                  5.336   0.418421   0.991012            3             335   \n",
            "5                  5.336   0.418421   0.991012            3            1576   \n",
            "6                  5.336   0.418421   0.991012            3            1524   \n",
            "7                  5.336   0.418421   0.991012            3            1097   \n",
            "8                  5.336   0.418421   0.991012            3            1097   \n",
            "9                  4.735   0.282110   0.989702           11             738   \n",
            "10                 4.735   0.282110   0.989702           11             738   \n",
            "11                 4.735   0.282110   0.989702           11             371   \n",
            "12                 5.225   0.288516   1.074988           19             884   \n",
            "13                 5.225   0.288516   1.074988           19             362   \n",
            "14                 5.225   0.288516   1.074988           19             362   \n",
            "15                 5.225   0.288516   1.074988           19             362   \n",
            "16                 5.225   0.288516   1.074988           19             362   \n",
            "17                 5.225   0.288516   1.074988           19             441   \n",
            "18                 5.225   0.288516   1.074988           19             548   \n",
            "19                 5.225   0.288516   1.074988           19            1251   \n",
            "20                 5.225   0.288516   1.074988           19            1418   \n",
            "21                 5.225   0.288516   1.074988           19            1251   \n",
            "22                 5.225   0.288516   1.074988           19            1418   \n",
            "23                 5.225   0.288516   1.074988           19            1251   \n",
            "24                 5.225   0.288516   1.074988           19            1251   \n",
            "25                 5.225   0.288516   1.074988           19             362   \n",
            "26                 5.225   0.288516   1.074988           19             362   \n",
            "27                 5.225   0.288516   1.074988           19             362   \n",
            "28                 5.225   0.288516   1.074988           19             362   \n",
            "29                 5.225   0.288516   1.074988           19             362   \n",
            "...                  ...        ...        ...          ...             ...   \n",
            "10374              3.593   0.249464   0.591683           17            1679   \n",
            "10375              3.593   0.249464   0.591683           17             140   \n",
            "10376              3.593   0.249464   0.591683           17             111   \n",
            "10377              3.593   0.249464   0.591683           17             155   \n",
            "10378              3.593   0.249464   0.591683           17             428   \n",
            "10379              3.593   0.249464   0.591683           17            1890   \n",
            "10380              3.593   0.249464   0.591683           17            1621   \n",
            "10381              3.593   0.249464   0.591683           17            1522   \n",
            "10382              3.593   0.249464   0.591683           17            1277   \n",
            "10383              3.593   0.249464   0.591683           17             411   \n",
            "10384              3.593   0.249464   0.591683           17            1621   \n",
            "10385              3.593   0.249464   0.591683           17            1621   \n",
            "10386              3.593   0.249464   0.591683           17            1883   \n",
            "10387              3.593   0.249464   0.591683           17            1621   \n",
            "10388              3.593   0.249464   0.591683           17            1621   \n",
            "10389              3.593   0.249464   0.591683           17            1621   \n",
            "10390              3.593   0.249464   0.591683           17            1621   \n",
            "10391              3.593   0.249464   0.591683           17            1621   \n",
            "10392              3.593   0.249464   0.591683           17            1621   \n",
            "10393              3.593   0.249464   0.591683           17            1621   \n",
            "10394              3.593   0.249464   0.591683           17            1621   \n",
            "10395              3.593   0.249464   0.591683           17             163   \n",
            "10396              3.593   0.249464   0.591683           17            1388   \n",
            "10397              3.593   0.249464   0.591683           17            1621   \n",
            "10398              3.593   0.249464   0.591683           17            1883   \n",
            "10399              3.593   0.249464   0.591683           17            1172   \n",
            "10400              3.593   0.249464   0.591683           17              88   \n",
            "10401              3.593   0.249464   0.591683           17             955   \n",
            "10402              3.593   0.249464   0.591683           17             505   \n",
            "10403              3.593   0.249464   0.591683           17            1323   \n",
            "\n",
            "       provstate_numerical  gname_numerical  \n",
            "0                       14                0  \n",
            "1                       14                0  \n",
            "2                       14                0  \n",
            "3                       14                3  \n",
            "4                       87                3  \n",
            "5                       87                3  \n",
            "6                       72                3  \n",
            "7                       72                3  \n",
            "8                       72                3  \n",
            "9                       93                3  \n",
            "10                      93                3  \n",
            "11                      53                3  \n",
            "12                      97                3  \n",
            "13                      32                3  \n",
            "14                      32                3  \n",
            "15                      32                3  \n",
            "16                      32                3  \n",
            "17                      32                3  \n",
            "18                      32                3  \n",
            "19                      32                3  \n",
            "20                      32                3  \n",
            "21                      32                3  \n",
            "22                      32                3  \n",
            "23                      32                3  \n",
            "24                      32                3  \n",
            "25                      32                3  \n",
            "26                      32                3  \n",
            "27                      32                3  \n",
            "28                      32                3  \n",
            "29                      32                3  \n",
            "...                    ...              ...  \n",
            "10374                  128                2  \n",
            "10375                  122                1  \n",
            "10376                    7                2  \n",
            "10377                    7                2  \n",
            "10378                    7                2  \n",
            "10379                  122                2  \n",
            "10380                   13                2  \n",
            "10381                   57                1  \n",
            "10382                    0                1  \n",
            "10383                  122                1  \n",
            "10384                   13                2  \n",
            "10385                   13                2  \n",
            "10386                  116                2  \n",
            "10387                   13                2  \n",
            "10388                   13                2  \n",
            "10389                   13                2  \n",
            "10390                   13                2  \n",
            "10391                   13                2  \n",
            "10392                   13                2  \n",
            "10393                   13                2  \n",
            "10394                   13                2  \n",
            "10395                    9                2  \n",
            "10396                  128                2  \n",
            "10397                   13                2  \n",
            "10398                   40                2  \n",
            "10399                    9                2  \n",
            "10400                  128                2  \n",
            "10401                    9                2  \n",
            "10402                    9                2  \n",
            "10403                   92                2  \n",
            "\n",
            "[9490 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3kBySk3KuOr",
        "colab_type": "text"
      },
      "source": [
        "#Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PwEffIqhsqS",
        "colab_type": "text"
      },
      "source": [
        "###KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pb0uJrawlxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn_classifier(labels_train, labels_test, data_train, data_test):\n",
        "  \n",
        "  scaler = StandardScaler()  \n",
        "  scaler.fit(data_train)\n",
        "\n",
        "  data_train = scaler.transform(data_train)  \n",
        "  data_test = scaler.transform(data_test)  \n",
        "\n",
        "  acc = 0\n",
        "\n",
        "  for i in range(3,1000):\n",
        "\n",
        "    # Create KNN Classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors = i)\n",
        "\n",
        "    # Train the model using the training sets\n",
        "    knn.fit(data_train, labels_train)\n",
        "\n",
        "    # Predict the response for test dataset\n",
        "    y_pred = knn.predict(data_test)\n",
        "\n",
        "    # Model Accuracy, how often is the classifier correct?\n",
        "    curr_acc =  metrics.accuracy_score(labels_test, y_pred)\n",
        "    if curr_acc > acc:\n",
        "      acc = curr_acc\n",
        "      print(\"Accuracy:\", acc)\n",
        "      print(confusion_matrix(labels_test, y_pred))  \n",
        "      print(classification_report(labels_test, y_pred))\n",
        "      print(i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH9dHA6XCggw",
        "colab_type": "text"
      },
      "source": [
        "###Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCTZXpe2GFek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def naive_bayes_classifier(labels_train, labels_test, data_train, data_test):\n",
        "  \n",
        "  # Create a  Naive Bayes Classifier\n",
        "  clf = GaussianNB()\n",
        "\n",
        "  # Train the model using the training sets\n",
        "  clf.fit(data_train, labels_train)\n",
        "\n",
        "  # Predict the response for test dataset\n",
        "  y_pred = clf.predict(data_test)\n",
        "\n",
        "  print(\"Accuracy:\", metrics.accuracy_score(labels_test, y_pred))\n",
        "  print(confusion_matrix(labels_test, y_pred))  \n",
        "  print(classification_report(labels_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DewW6hNCqDC",
        "colab_type": "text"
      },
      "source": [
        "### Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DmEYYXO4BUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_forest_classifier(labels_train, labels_test, data_train, data_test):\n",
        "  \n",
        "  acc = 0\n",
        "  for i in range(3,1000):\n",
        "    # Create a Gaussian Classifier\n",
        "    clf = RandomForestClassifier(n_estimators = i)\n",
        "\n",
        "    # Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "    clf.fit(data_train, labels_train)    \n",
        "    y_pred=clf.predict(data_test)\n",
        "\n",
        "    curr_acc =  metrics.accuracy_score(labels_test, y_pred)\n",
        "    if curr_acc > acc:\n",
        "      acc = curr_acc\n",
        "      print(\"Accuracy:\", acc)\n",
        "      print(confusion_matrix(labels_test, y_pred))  \n",
        "      print(classification_report(labels_test, y_pred))\n",
        "      print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c_kOOg_C8pv",
        "colab_type": "text"
      },
      "source": [
        "###Decision tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFI0_1-b4u2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decision_tree_classifier(labels_train, labels_test, data_train, data_test):\n",
        " \n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf.fit(data_train, labels_train)    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "  y_pred=clf.predict(data_test)\n",
        "\n",
        "  print(\"Accuracy:\", metrics.accuracy_score(labels_test, y_pred))\n",
        "  print(confusion_matrix(labels_test, y_pred))  \n",
        "  print(classification_report(labels_test, y_pred))\n",
        "\n",
        "  # CART (Classification and Regression Trees) is very similar to C4.5, \n",
        "  # but it differs in that it supports numerical target variables (regression) and does not compute rule sets. \n",
        "  # CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.\n",
        "  # scikit-learn uses an optimised version of the CART algorithm."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyHb7Bt7Vovm",
        "colab_type": "text"
      },
      "source": [
        "###SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeUpFwtM9Ml0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm_classifier(labels_train, labels_test, data_train, data_test):\n",
        "  \n",
        "  scaler = StandardScaler()  \n",
        "  scaler.fit(data_train)\n",
        "\n",
        "  data_train = scaler.transform(data_train)  \n",
        "  data_test = scaler.transform(data_test)\n",
        "\n",
        "  print(data_train.shape)\n",
        "  print(labels_train.shape)\n",
        "  print(data_test.shape)\n",
        "  print(labels_test.shape)\n",
        "  \n",
        "  print(labels_train)\n",
        "  print(data_train)\n",
        "\n",
        "  \n",
        "  #Create a svm Classifier\n",
        "  clf = svm.SVC(kernel = 'linear') # Linear Kernel\n",
        "  print(\"create\")\n",
        "  \n",
        "  #Train the model using the training sets\n",
        "  clf.fit(data_train, labels_train)\n",
        "  print(\"fit\")\n",
        "  \n",
        "  #Predict the response for test dataset\n",
        "  y_pred = clf.predict(data_test)\n",
        "  print(\"predict\")\n",
        "\n",
        " # Model Accuracy: how often is the classifier correct?\n",
        "  print(\"Accuracy:\", metrics.accuracy_score(labels_test, y_pred))\n",
        "  print(confusion_matrix(labels_test, y_pred))  \n",
        "  print(classification_report(labels_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG4F7-faK4ag",
        "colab_type": "text"
      },
      "source": [
        "# Calling Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPi0no_cHquU",
        "colab_type": "text"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVRsqTnPHyEG",
        "colab_type": "code",
        "outputId": "2badba65-feff-470d-cafc-042e08f42f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4865
        }
      },
      "source": [
        "# training knn classifier on gtd only\n",
        "knn_classifier(labels_train1, labels_test1, data_train1, data_test1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7512135922330098\n",
            "[[  0   0   0   0   0]\n",
            " [  0  39   2   1   2]\n",
            " [  0  44 104   8   2]\n",
            " [274   2   5 973  37]\n",
            " [  1   9   4  19 122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.41      0.89      0.57        44\n",
            "           2       0.90      0.66      0.76       158\n",
            "           3       0.97      0.75      0.85      1291\n",
            "           4       0.75      0.79      0.77       155\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      1648\n",
            "   macro avg       0.61      0.62      0.59      1648\n",
            "weighted avg       0.93      0.75      0.83      1648\n",
            "\n",
            "3\n",
            "Accuracy: 0.8258495145631068\n",
            "[[   0    0    0    0    0]\n",
            " [   0   38    3    0    3]\n",
            " [   2   32  114    6    4]\n",
            " [ 156    3    6 1089   37]\n",
            " [   1    6    9   19  120]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.48      0.86      0.62        44\n",
            "           2       0.86      0.72      0.79       158\n",
            "           3       0.98      0.84      0.91      1291\n",
            "           4       0.73      0.77      0.75       155\n",
            "\n",
            "   micro avg       0.83      0.83      0.83      1648\n",
            "   macro avg       0.61      0.64      0.61      1648\n",
            "weighted avg       0.93      0.83      0.87      1648\n",
            "\n",
            "5\n",
            "Accuracy: 0.8343446601941747\n",
            "[[   0    0    0    0    0]\n",
            " [   0   35    6    1    2]\n",
            " [   0   36  103   13    6]\n",
            " [ 130    3    6 1110   42]\n",
            " [   1    3    8   16  127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.45      0.80      0.58        44\n",
            "           2       0.84      0.65      0.73       158\n",
            "           3       0.97      0.86      0.91      1291\n",
            "           4       0.72      0.82      0.77       155\n",
            "\n",
            "   micro avg       0.83      0.83      0.83      1648\n",
            "   macro avg       0.60      0.63      0.60      1648\n",
            "weighted avg       0.92      0.83      0.87      1648\n",
            "\n",
            "7\n",
            "Accuracy: 0.8598300970873787\n",
            "[[   0    0    0    0    0]\n",
            " [   0   35    5    1    3]\n",
            " [   0   43   95   13    7]\n",
            " [  73    4    7 1162   45]\n",
            " [   1    3   11   15  125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.41      0.80      0.54        44\n",
            "           2       0.81      0.60      0.69       158\n",
            "           3       0.98      0.90      0.94      1291\n",
            "           4       0.69      0.81      0.75       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.58      0.62      0.58      1648\n",
            "weighted avg       0.92      0.86      0.88      1648\n",
            "\n",
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8610436893203883\n",
            "[[   0    0    0    0    0]\n",
            " [   0   30    4    1    9]\n",
            " [   0   25   89   16   28]\n",
            " [  23   10   23 1190   45]\n",
            " [   1    9   15   20  110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.41      0.68      0.51        44\n",
            "           2       0.68      0.56      0.62       158\n",
            "           3       0.97      0.92      0.95      1291\n",
            "           4       0.57      0.71      0.63       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.53      0.58      0.54      1648\n",
            "weighted avg       0.89      0.86      0.87      1648\n",
            "\n",
            "47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8628640776699029\n",
            "[[   0    0    0    0    0]\n",
            " [   0   31    5    1    7]\n",
            " [   0   25   87   17   29]\n",
            " [  17   11   23 1194   46]\n",
            " [   1    9   15   20  110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.41      0.70      0.52        44\n",
            "           2       0.67      0.55      0.60       158\n",
            "           3       0.97      0.92      0.95      1291\n",
            "           4       0.57      0.71      0.63       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.52      0.58      0.54      1648\n",
            "weighted avg       0.89      0.86      0.87      1648\n",
            "\n",
            "49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8640776699029126\n",
            "[[   0    0    0    0    0]\n",
            " [   0   27    4    5    8]\n",
            " [   0   25   82   16   35]\n",
            " [   2   19   22 1208   40]\n",
            " [   0    5   16   27  107]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.36      0.61      0.45        44\n",
            "           2       0.66      0.52      0.58       158\n",
            "           3       0.96      0.94      0.95      1291\n",
            "           4       0.56      0.69      0.62       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.51      0.55      0.52      1648\n",
            "weighted avg       0.88      0.86      0.87      1648\n",
            "\n",
            "98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8646844660194175\n",
            "[[   0    0    0    0    0]\n",
            " [   0   24    4    8    8]\n",
            " [   0   16   81   22   39]\n",
            " [   1    3   27 1215   45]\n",
            " [   0    3   19   28  105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.52      0.55      0.53        44\n",
            "           2       0.62      0.51      0.56       158\n",
            "           3       0.95      0.94      0.95      1291\n",
            "           4       0.53      0.68      0.60       155\n",
            "\n",
            "   micro avg       0.86      0.86      0.86      1648\n",
            "   macro avg       0.53      0.54      0.53      1648\n",
            "weighted avg       0.87      0.86      0.87      1648\n",
            "\n",
            "196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8652912621359223\n",
            "[[  24    4    8    8]\n",
            " [  16   82   21   39]\n",
            " [   3   27 1215   46]\n",
            " [   3   19   28  105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.52      0.55      0.53        44\n",
            "           2       0.62      0.52      0.57       158\n",
            "           3       0.96      0.94      0.95      1291\n",
            "           4       0.53      0.68      0.59       155\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      1648\n",
            "   macro avg       0.66      0.67      0.66      1648\n",
            "weighted avg       0.87      0.87      0.87      1648\n",
            "\n",
            "198\n",
            "Accuracy: 0.866504854368932\n",
            "[[   0    0    0    0    0]\n",
            " [   0   24    4    8    8]\n",
            " [   0   16   83   20   39]\n",
            " [   1    3   27 1215   45]\n",
            " [   0    3   19   27  106]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.52      0.55      0.53        44\n",
            "           2       0.62      0.53      0.57       158\n",
            "           3       0.96      0.94      0.95      1291\n",
            "           4       0.54      0.68      0.60       155\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      1648\n",
            "   macro avg       0.53      0.54      0.53      1648\n",
            "weighted avg       0.87      0.87      0.87      1648\n",
            "\n",
            "199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8671116504854369\n",
            "[[   0    0    0    0    0]\n",
            " [   0   24    4    8    8]\n",
            " [   0   17   84   19   38]\n",
            " [   1    4   26 1216   44]\n",
            " [   0    4   19   27  105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.49      0.55      0.52        44\n",
            "           2       0.63      0.53      0.58       158\n",
            "           3       0.96      0.94      0.95      1291\n",
            "           4       0.54      0.68      0.60       155\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      1648\n",
            "   macro avg       0.52      0.54      0.53      1648\n",
            "weighted avg       0.87      0.87      0.87      1648\n",
            "\n",
            "212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8677184466019418\n",
            "[[  25    4    7    8]\n",
            " [  18   84   17   39]\n",
            " [   4   27 1217   43]\n",
            " [   4   20   27  104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.49      0.57      0.53        44\n",
            "           2       0.62      0.53      0.57       158\n",
            "           3       0.96      0.94      0.95      1291\n",
            "           4       0.54      0.67      0.60       155\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      1648\n",
            "   macro avg       0.65      0.68      0.66      1648\n",
            "weighted avg       0.88      0.87      0.87      1648\n",
            "\n",
            "225\n",
            "Accuracy: 0.8683252427184466\n",
            "[[  26    4    7    7]\n",
            " [  18   84   17   39]\n",
            " [   4   27 1217   43]\n",
            " [   4   20   27  104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.59      0.54        44\n",
            "           2       0.62      0.53      0.57       158\n",
            "           3       0.96      0.94      0.95      1291\n",
            "           4       0.54      0.67      0.60       155\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      1648\n",
            "   macro avg       0.66      0.68      0.67      1648\n",
            "weighted avg       0.88      0.87      0.87      1648\n",
            "\n",
            "228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f3abedcf6c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-6a869bfcb83b>\u001b[0m in \u001b[0;36mknn_classifier\u001b[0;34m(labels_train, labels_test, data_train, data_test)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Predict the response for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Model Accuracy, how often is the classifier correct?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 delayed_query(\n\u001b[1;32m    454\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             )\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Df0UdYVIkqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training knn classifier on gtd & happiness\n",
        "knn_classifier(labels_train2, labels_test2, data_train2, data_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBtA_0bsImCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training knn classifier on gtd & ethnic\n",
        "knn_classifier(labels_train3, labels_test3, data_train3, data_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncEFsiqIoKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training knn classifier on gtd, happiness & ethnic\n",
        "knn_classifier(labels_train4, labels_test4, data_train4, data_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCglSnMkJDbV",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pyjduYjJHFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "f64023a7-a8db-457f-ddaa-78fbc4624bb6"
      },
      "source": [
        "# training naive classifier on gtd only\n",
        "naive_bayes_classifier(labels_train1, labels_test1, data_train1, data_test1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3446601941747573\n",
            "[[  0   0   0   0   0]\n",
            " [  0  41   3   0   0]\n",
            " [  0  77  52  29   0]\n",
            " [817   0  28 347  99]\n",
            " [  7   0  16   4 128]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.35      0.93      0.51        44\n",
            "           2       0.53      0.33      0.40       158\n",
            "           3       0.91      0.27      0.42      1291\n",
            "           4       0.56      0.83      0.67       155\n",
            "\n",
            "   micro avg       0.34      0.34      0.34      1648\n",
            "   macro avg       0.47      0.47      0.40      1648\n",
            "weighted avg       0.83      0.34      0.44      1648\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0AhyFrqJPRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training naive classifier on gtd & happiness\n",
        "naive_bayes_classifier(labels_train2, labels_test2, data_train2, data_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVQ57GMPJUe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training naive classifier on gtd & ethnic\n",
        "naive_bayes_classifier(labels_train3, labels_test3, data_train3, data_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCzUxhykJVyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training naive classifier on gtd, happiness & ethnic\n",
        "naive_bayes_classifier(labels_train4, labels_test4, data_train4, data_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orw3jIStJs9N",
        "colab_type": "text"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zEBNfqJxz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training random forest classifier on gtd only\n",
        "random_forest_classifier(labels_train1, labels_test1, data_train1, data_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Om3xxEYJ6r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training random forest classifier on gtd & happiness\n",
        "random_forest_classifier(labels_train2, labels_test2, data_train2, data_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9jGqkoJ7ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training random forest classifier on gtd & ethnic\n",
        "random_forest_classifier(labels_train3, labels_test3, data_train3, data_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaONVPF6J7lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training random forest classifier on gtd, happiness & ethnic\n",
        "random_forest_classifier(labels_train4, labels_test4, data_train4, data_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw3KmVuwLEH3",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl4Gwm8jLPGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training decision tree classifier on gtd only\n",
        "decision_tree_classifier(labels_train1, labels_test1, data_train1, data_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wJHowEALRRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training decision tree classifier on gtd & happiness\n",
        "decision_tree_classifier(labels_train2, labels_test2, data_train2, data_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0xneHjzLS8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training decision tree classifier on gtd & ethnic\n",
        "decision_tree_classifier(labels_train3, labels_test3, data_train3, data_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNBJ3o9cLVH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training decision tree classifier on gtd, happiness & ethnic\n",
        "decision_tree_classifier(labels_train4, labels_test4, data_train4, data_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eesT4I_fLgXq",
        "colab_type": "text"
      },
      "source": [
        "###SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNWR1rLLjY7",
        "colab_type": "code",
        "outputId": "4013fb75-b2bd-4ad0-a865-a136f6619327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        }
      },
      "source": [
        "# training svm classifier on gtd only\n",
        "svm_classifier(labels_train1, labels_test1, data_train1, data_test1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7842, 6)\n",
            "(7842,)\n",
            "(1648, 6)\n",
            "(1648,)\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        3\n",
            "4        3\n",
            "5        3\n",
            "6        3\n",
            "7        3\n",
            "8        3\n",
            "9        3\n",
            "10       3\n",
            "11       3\n",
            "12       3\n",
            "13       3\n",
            "14       3\n",
            "15       3\n",
            "16       3\n",
            "17       3\n",
            "18       3\n",
            "19       3\n",
            "20       3\n",
            "21       3\n",
            "22       3\n",
            "23       3\n",
            "24       3\n",
            "25       3\n",
            "26       3\n",
            "27       3\n",
            "28       3\n",
            "29       3\n",
            "        ..\n",
            "10201    2\n",
            "10202    1\n",
            "10203    2\n",
            "10204    2\n",
            "10205    2\n",
            "10206    2\n",
            "10207    2\n",
            "10208    2\n",
            "10209    2\n",
            "10210    2\n",
            "10211    2\n",
            "10212    1\n",
            "10213    2\n",
            "10214    2\n",
            "10215    2\n",
            "10216    2\n",
            "10217    2\n",
            "10218    2\n",
            "10219    2\n",
            "10220    2\n",
            "10221    2\n",
            "10222    2\n",
            "10223    2\n",
            "10224    2\n",
            "10225    2\n",
            "10226    2\n",
            "10227    1\n",
            "10228    1\n",
            "10229    2\n",
            "10230    2\n",
            "Name: gname_numerical, Length: 7842, dtype: int64\n",
            "[[-0.77395716 -1.30076745 -0.39136671 -0.36389531 -1.40528775 -1.05382212]\n",
            " [-0.77395716 -1.30076745 -0.39136671 -0.36389531 -1.40528775 -1.05382212]\n",
            " [-0.77395716 -1.30076745 -0.39136671 -0.36389531 -1.40528775 -1.05382212]\n",
            " ...\n",
            " [ 1.30087293  0.83621064  2.14927713  2.44253021  1.31358901  1.33403124]\n",
            " [ 1.30087293  0.17867892  0.33453153  1.50705504  0.861593   -1.07593187]\n",
            " [ 1.30087293  0.83621064 -0.39136671 -0.36389531  0.34749067  0.67073864]]\n",
            "create\n",
            "fit\n",
            "predict\n",
            "Accuracy: 0.9326456310679612\n",
            "[[  34   10    0    0]\n",
            " [  52   77   29    0]\n",
            " [   0    0 1284    7]\n",
            " [   0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.77      0.52        44\n",
            "           2       0.89      0.49      0.63       158\n",
            "           3       0.97      0.99      0.98      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.93      0.93      0.93      1648\n",
            "   macro avg       0.80      0.79      0.77      1648\n",
            "weighted avg       0.94      0.93      0.93      1648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arcZF2CrLmYw",
        "colab_type": "code",
        "outputId": "b78409f4-a6db-4269-ceb5-8ff16127a15a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1805
        }
      },
      "source": [
        "# training svm classifier on gtd & happiness\n",
        "svm_classifier(labels_train2, labels_test2, data_train2, data_test2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7842, 15)\n",
            "(7842,)\n",
            "(1648, 15)\n",
            "(1648,)\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        3\n",
            "4        3\n",
            "5        3\n",
            "6        3\n",
            "7        3\n",
            "8        3\n",
            "9        3\n",
            "10       3\n",
            "11       3\n",
            "12       3\n",
            "13       3\n",
            "14       3\n",
            "15       3\n",
            "16       3\n",
            "17       3\n",
            "18       3\n",
            "19       3\n",
            "20       3\n",
            "21       3\n",
            "22       3\n",
            "23       3\n",
            "24       3\n",
            "25       3\n",
            "26       3\n",
            "27       3\n",
            "28       3\n",
            "29       3\n",
            "        ..\n",
            "10201    2\n",
            "10202    1\n",
            "10203    2\n",
            "10204    2\n",
            "10205    2\n",
            "10206    2\n",
            "10207    2\n",
            "10208    2\n",
            "10209    2\n",
            "10210    2\n",
            "10211    2\n",
            "10212    1\n",
            "10213    2\n",
            "10214    2\n",
            "10215    2\n",
            "10216    2\n",
            "10217    2\n",
            "10218    2\n",
            "10219    2\n",
            "10220    2\n",
            "10221    2\n",
            "10222    2\n",
            "10223    2\n",
            "10224    2\n",
            "10225    2\n",
            "10226    2\n",
            "10227    1\n",
            "10228    1\n",
            "10229    2\n",
            "10230    2\n",
            "Name: gname_numerical, Length: 7842, dtype: int64\n",
            "[[-7.73957156e-01 -1.30076745e+00 -3.91366712e-01 ... -6.71243985e-04\n",
            "  -1.40528775e+00 -1.05382212e+00]\n",
            " [-7.73957156e-01 -1.30076745e+00 -3.91366712e-01 ... -6.71243985e-04\n",
            "  -1.40528775e+00 -1.05382212e+00]\n",
            " [-7.73957156e-01 -1.30076745e+00 -3.91366712e-01 ... -6.71243985e-04\n",
            "  -1.40528775e+00 -1.05382212e+00]\n",
            " ...\n",
            " [ 1.30087293e+00  8.36210641e-01  2.14927713e+00 ... -1.67458230e+00\n",
            "   1.31358901e+00  1.33403124e+00]\n",
            " [ 1.30087293e+00  1.78678921e-01  3.34531527e-01 ... -1.67458230e+00\n",
            "   8.61593003e-01 -1.07593187e+00]\n",
            " [ 1.30087293e+00  8.36210641e-01 -3.91366712e-01 ... -1.67458230e+00\n",
            "   3.47490671e-01  6.70738643e-01]]\n",
            "create\n",
            "fit\n",
            "predict\n",
            "Accuracy: 0.9502427184466019\n",
            "[[  34   10    0    0]\n",
            " [  52  106    0    0]\n",
            " [   0    0 1284    7]\n",
            " [   0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.77      0.52        44\n",
            "           2       0.91      0.67      0.77       158\n",
            "           3       0.99      0.99      0.99      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      1648\n",
            "   macro avg       0.81      0.84      0.81      1648\n",
            "weighted avg       0.96      0.95      0.95      1648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VAyIpkeLnfm",
        "colab_type": "code",
        "outputId": "50eb1976-7152-4a5d-eb0c-0afb8d0dccdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1805
        }
      },
      "source": [
        "# training svm classifier on gtd & ethnic\n",
        "svm_classifier(labels_train3, labels_test3, data_train3, data_test3)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7842, 7)\n",
            "(7842,)\n",
            "(1648, 7)\n",
            "(1648,)\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        3\n",
            "4        3\n",
            "5        3\n",
            "6        3\n",
            "7        3\n",
            "8        3\n",
            "9        3\n",
            "10       3\n",
            "11       3\n",
            "12       3\n",
            "13       3\n",
            "14       3\n",
            "15       3\n",
            "16       3\n",
            "17       3\n",
            "18       3\n",
            "19       3\n",
            "20       3\n",
            "21       3\n",
            "22       3\n",
            "23       3\n",
            "24       3\n",
            "25       3\n",
            "26       3\n",
            "27       3\n",
            "28       3\n",
            "29       3\n",
            "        ..\n",
            "10201    2\n",
            "10202    1\n",
            "10203    2\n",
            "10204    2\n",
            "10205    2\n",
            "10206    2\n",
            "10207    2\n",
            "10208    2\n",
            "10209    2\n",
            "10210    2\n",
            "10211    2\n",
            "10212    1\n",
            "10213    2\n",
            "10214    2\n",
            "10215    2\n",
            "10216    2\n",
            "10217    2\n",
            "10218    2\n",
            "10219    2\n",
            "10220    2\n",
            "10221    2\n",
            "10222    2\n",
            "10223    2\n",
            "10224    2\n",
            "10225    2\n",
            "10226    2\n",
            "10227    1\n",
            "10228    1\n",
            "10229    2\n",
            "10230    2\n",
            "Name: gname_numerical, Length: 7842, dtype: int64\n",
            "[[-0.77395716 -1.30076745 -0.39136671 ... -0.94071701 -1.40528775\n",
            "  -1.05382212]\n",
            " [-0.77395716 -1.30076745 -0.39136671 ... -0.94071701 -1.40528775\n",
            "  -1.05382212]\n",
            " [-0.77395716 -1.30076745 -0.39136671 ... -0.94071701 -1.40528775\n",
            "  -1.05382212]\n",
            " ...\n",
            " [ 1.30087293  0.83621064  2.14927713 ...  1.59499227  1.31358901\n",
            "   1.33403124]\n",
            " [ 1.30087293  0.17867892  0.33453153 ...  1.59499227  0.861593\n",
            "  -1.07593187]\n",
            " [ 1.30087293  0.83621064 -0.39136671 ...  1.59499227  0.34749067\n",
            "   0.67073864]]\n",
            "create\n",
            "fit\n",
            "predict\n",
            "Accuracy: 0.9326456310679612\n",
            "[[  34   10    0    0]\n",
            " [  52   77   29    0]\n",
            " [   0    0 1284    7]\n",
            " [   0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.77      0.52        44\n",
            "           2       0.89      0.49      0.63       158\n",
            "           3       0.97      0.99      0.98      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.93      0.93      0.93      1648\n",
            "   macro avg       0.80      0.79      0.77      1648\n",
            "weighted avg       0.94      0.93      0.93      1648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R6ldjO4LopO",
        "colab_type": "code",
        "outputId": "446fc363-7fbe-4225-efd2-353d6955b672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1805
        }
      },
      "source": [
        "# training svm classifier on gtd, happiness & ethnic\n",
        "svm_classifier(labels_train4, labels_test4, data_train4, data_test4)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7842, 16)\n",
            "(7842,)\n",
            "(1648, 16)\n",
            "(1648,)\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        3\n",
            "4        3\n",
            "5        3\n",
            "6        3\n",
            "7        3\n",
            "8        3\n",
            "9        3\n",
            "10       3\n",
            "11       3\n",
            "12       3\n",
            "13       3\n",
            "14       3\n",
            "15       3\n",
            "16       3\n",
            "17       3\n",
            "18       3\n",
            "19       3\n",
            "20       3\n",
            "21       3\n",
            "22       3\n",
            "23       3\n",
            "24       3\n",
            "25       3\n",
            "26       3\n",
            "27       3\n",
            "28       3\n",
            "29       3\n",
            "        ..\n",
            "10201    2\n",
            "10202    1\n",
            "10203    2\n",
            "10204    2\n",
            "10205    2\n",
            "10206    2\n",
            "10207    2\n",
            "10208    2\n",
            "10209    2\n",
            "10210    2\n",
            "10211    2\n",
            "10212    1\n",
            "10213    2\n",
            "10214    2\n",
            "10215    2\n",
            "10216    2\n",
            "10217    2\n",
            "10218    2\n",
            "10219    2\n",
            "10220    2\n",
            "10221    2\n",
            "10222    2\n",
            "10223    2\n",
            "10224    2\n",
            "10225    2\n",
            "10226    2\n",
            "10227    1\n",
            "10228    1\n",
            "10229    2\n",
            "10230    2\n",
            "Name: gname_numerical, Length: 7842, dtype: int64\n",
            "[[-0.77395716 -1.30076745 -0.39136671 ... -0.94071701 -1.40528775\n",
            "  -1.05382212]\n",
            " [-0.77395716 -1.30076745 -0.39136671 ... -0.94071701 -1.40528775\n",
            "  -1.05382212]\n",
            " [-0.77395716 -1.30076745 -0.39136671 ... -0.94071701 -1.40528775\n",
            "  -1.05382212]\n",
            " ...\n",
            " [ 1.30087293  0.83621064  2.14927713 ...  1.59499227  1.31358901\n",
            "   1.33403124]\n",
            " [ 1.30087293  0.17867892  0.33453153 ...  1.59499227  0.861593\n",
            "  -1.07593187]\n",
            " [ 1.30087293  0.83621064 -0.39136671 ...  1.59499227  0.34749067\n",
            "   0.67073864]]\n",
            "create\n",
            "fit\n",
            "predict\n",
            "Accuracy: 0.9502427184466019\n",
            "[[  34   10    0    0]\n",
            " [  52  106    0    0]\n",
            " [   0    0 1284    7]\n",
            " [   0    0   13  142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.77      0.52        44\n",
            "           2       0.91      0.67      0.77       158\n",
            "           3       0.99      0.99      0.99      1291\n",
            "           4       0.95      0.92      0.93       155\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      1648\n",
            "   macro avg       0.81      0.84      0.81      1648\n",
            "weighted avg       0.96      0.95      0.95      1648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}